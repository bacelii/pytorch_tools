{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose: Implementation fo DiffPool\n",
    "graph coarsening manner\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datajoint as dj\n",
    "import trimesh\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from os import sys\n",
    "#sys.path.append(\"/meshAfterParty/meshAfterParty\")\n",
    "sys.path.append(\"/python_tools/python_tools\")\n",
    "sys.path.append(\"/machine_learning_tools/machine_learning_tools/\")\n",
    "sys.path.append(\"/pytorch_tools/pytorch_tools/\")\n",
    "sys.path.append(\"/neuron_morphology_tools/neuron_morphology_tools/\")\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/m65_full/df_morphometrics.pbz2'),\n",
       " PosixPath('data/m65_full/df_cell_type_fine.pbz2')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"./data/m65_full/\")\n",
    "list(data_path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python_tools modules\n",
    "import system_utils as su\n",
    "import pandas_utils as pu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_utils as nu\n",
    "import networkx_utils as xu\n",
    "from tqdm_utils import tqdm\n",
    "\n",
    "#neuron_morphology_tools modules\n",
    "import neuron_nx_io as nxio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import transforms\n",
    "\n",
    "# for the dataset object\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import DenseDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    }
   ],
   "source": [
    "#pytorch_tools modules\n",
    "import preprocessing_utils as pret\n",
    "import geometric_models as gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Choosing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device = {device}\")\n",
    "\n",
    "with_skeleton = True\n",
    "\n",
    "features_to_delete = [\n",
    "    \"mesh_volume\",\n",
    "    \"apical_label\",\n",
    "    \"basal_label\",\n",
    "]\n",
    "\n",
    "if not with_skeleton:\n",
    "    features_to_delete +=[\n",
    "        \"skeleton_vector_downstream_phi\",      \n",
    "        \"skeleton_vector_downstream_theta\",    \n",
    "        \"skeleton_vector_upstream_phi\",        \n",
    "        \"skeleton_vector_upstream_theta\",  \n",
    "    ]\n",
    "\n",
    "features_to_keep = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Loading the Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_task = \"cell_type_fine\"\n",
    "label_name = None\n",
    "graph_label = \"cell_type_fine_label\"\n",
    "data_file = \"df_cell_type_fine.pbz2\"\n",
    "dense_adj = False\n",
    "directed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>split_index</th>\n",
       "      <th>nucleus_id</th>\n",
       "      <th>external_layer</th>\n",
       "      <th>external_visual_area</th>\n",
       "      <th>cell_type_fine</th>\n",
       "      <th>cell_type_fine_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>864691134277239760</td>\n",
       "      <td>0</td>\n",
       "      <td>89719</td>\n",
       "      <td>LAYER_6</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_0'], 'features': ['mesh_vol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>864691134339067925</td>\n",
       "      <td>0</td>\n",
       "      <td>624899</td>\n",
       "      <td>LAYER_6</td>\n",
       "      <td>AL</td>\n",
       "      <td>[{'nodelist': ['L0_1', 'L0_0', 'L0_2'], 'featu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864691134366116139</td>\n",
       "      <td>0</td>\n",
       "      <td>476756</td>\n",
       "      <td>WHITE_MATTER</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L0_6'], 'features': ['mesh_vol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864691134378215335</td>\n",
       "      <td>0</td>\n",
       "      <td>3799</td>\n",
       "      <td>LAYER_2/3</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_1', 'L0_0', 'L0_2'], 'featu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864691134527727930</td>\n",
       "      <td>0</td>\n",
       "      <td>631380</td>\n",
       "      <td>WHITE_MATTER</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L0_0'], 'features': ['mesh_vol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60448</th>\n",
       "      <td>864691137197334593</td>\n",
       "      <td>0</td>\n",
       "      <td>376218</td>\n",
       "      <td>LAYER_6</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_5',...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60449</th>\n",
       "      <td>864691137197344065</td>\n",
       "      <td>0</td>\n",
       "      <td>191436</td>\n",
       "      <td>LAYER_2/3</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_0', 'L0_1', 'L0_4', 'L0_6',...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60450</th>\n",
       "      <td>864691137197345345</td>\n",
       "      <td>0</td>\n",
       "      <td>584463</td>\n",
       "      <td>LAYER_2/3</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L0_13', 'L4_5', 'L0_8', 'L2_5'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60451</th>\n",
       "      <td>864691137197353281</td>\n",
       "      <td>0</td>\n",
       "      <td>591241</td>\n",
       "      <td>LAYER_5</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L4_6', 'L1_10', 'L3_4', 'L0_10...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60452</th>\n",
       "      <td>864691137197364801</td>\n",
       "      <td>0</td>\n",
       "      <td>488097</td>\n",
       "      <td>LAYER_2/3</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L0_9', 'L0_8', 'L0_10', 'L0_6'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60453 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               segment_id  split_index  nucleus_id external_layer  \\\n",
       "0      864691134277239760            0       89719        LAYER_6   \n",
       "1      864691134339067925            0      624899        LAYER_6   \n",
       "2      864691134366116139            0      476756   WHITE_MATTER   \n",
       "3      864691134378215335            0        3799      LAYER_2/3   \n",
       "4      864691134527727930            0      631380   WHITE_MATTER   \n",
       "...                   ...          ...         ...            ...   \n",
       "60448  864691137197334593            0      376218        LAYER_6   \n",
       "60449  864691137197344065            0      191436      LAYER_2/3   \n",
       "60450  864691137197345345            0      584463      LAYER_2/3   \n",
       "60451  864691137197353281            0      591241        LAYER_5   \n",
       "60452  864691137197364801            0      488097      LAYER_2/3   \n",
       "\n",
       "      external_visual_area                                     cell_type_fine  \\\n",
       "0                       V1  [{'nodelist': ['L0_0'], 'features': ['mesh_vol...   \n",
       "1                       AL  [{'nodelist': ['L0_1', 'L0_0', 'L0_2'], 'featu...   \n",
       "2                       RL  [{'nodelist': ['L0_6'], 'features': ['mesh_vol...   \n",
       "3                       V1  [{'nodelist': ['L0_1', 'L0_0', 'L0_2'], 'featu...   \n",
       "4                       RL  [{'nodelist': ['L0_0'], 'features': ['mesh_vol...   \n",
       "...                    ...                                                ...   \n",
       "60448                   V1  [{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_5',...   \n",
       "60449                   V1  [{'nodelist': ['L0_0', 'L0_1', 'L0_4', 'L0_6',...   \n",
       "60450                   RL  [{'nodelist': ['L0_13', 'L4_5', 'L0_8', 'L2_5'...   \n",
       "60451                   RL  [{'nodelist': ['L4_6', 'L1_10', 'L3_4', 'L0_10...   \n",
       "60452                   RL  [{'nodelist': ['L0_9', 'L0_8', 'L0_10', 'L0_6'...   \n",
       "\n",
       "      cell_type_fine_label  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "...                    ...  \n",
       "60448                  NaN  \n",
       "60449                  NaN  \n",
       "60450                  NaN  \n",
       "60451                  NaN  \n",
       "60452                  NaN  \n",
       "\n",
       "[60453 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filepath = Path(data_path) / Path(data_file)\n",
    "\n",
    "data_df = su.decompress_pickle(data_filepath)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNote the cell_type_fine is the column\\nthat has all of the graph data stored\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Note the cell_type_fine is the column\n",
    "that has all of the graph data stored\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>split_index</th>\n",
       "      <th>nucleus_id</th>\n",
       "      <th>external_layer</th>\n",
       "      <th>external_visual_area</th>\n",
       "      <th>cell_type_fine</th>\n",
       "      <th>cell_type_fine_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>864691134884748026</td>\n",
       "      <td>0</td>\n",
       "      <td>366181</td>\n",
       "      <td>LAYER_5</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_10', 'L0_11', 'L0_12', 'L0_...</td>\n",
       "      <td>4P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>864691134884761338</td>\n",
       "      <td>0</td>\n",
       "      <td>458241</td>\n",
       "      <td>LAYER_4</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_3',...</td>\n",
       "      <td>23P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>864691134884769786</td>\n",
       "      <td>0</td>\n",
       "      <td>592718</td>\n",
       "      <td>LAYER_5</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L0_18', 'L0_11', 'L0_17', 'L0_...</td>\n",
       "      <td>5P_IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>864691134884879610</td>\n",
       "      <td>0</td>\n",
       "      <td>304873</td>\n",
       "      <td>LAYER_5</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L2_4', 'L1_1', 'L0_3', 'L1_6',...</td>\n",
       "      <td>IT_short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>864691134884945146</td>\n",
       "      <td>0</td>\n",
       "      <td>63499</td>\n",
       "      <td>LAYER_2/3</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_3',...</td>\n",
       "      <td>23P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60416</th>\n",
       "      <td>864691137197239105</td>\n",
       "      <td>0</td>\n",
       "      <td>262000</td>\n",
       "      <td>LAYER_4</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_3',...</td>\n",
       "      <td>4P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60417</th>\n",
       "      <td>864691137197241665</td>\n",
       "      <td>0</td>\n",
       "      <td>308938</td>\n",
       "      <td>LAYER_6</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L1_4', 'L0_18', 'L4_1', 'L0_16...</td>\n",
       "      <td>Unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60433</th>\n",
       "      <td>864691137197306177</td>\n",
       "      <td>0</td>\n",
       "      <td>304611</td>\n",
       "      <td>LAYER_5</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_1', 'L0_3', 'L0_6', 'L0_0',...</td>\n",
       "      <td>5P_NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60442</th>\n",
       "      <td>864691137197321281</td>\n",
       "      <td>0</td>\n",
       "      <td>434601</td>\n",
       "      <td>LAYER_5</td>\n",
       "      <td>RL</td>\n",
       "      <td>[{'nodelist': ['L0_3', 'L3_3', 'L2_2', 'L2_3',...</td>\n",
       "      <td>6P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60445</th>\n",
       "      <td>864691137197329985</td>\n",
       "      <td>0</td>\n",
       "      <td>260468</td>\n",
       "      <td>LAYER_4</td>\n",
       "      <td>V1</td>\n",
       "      <td>[{'nodelist': ['L0_3', 'L1_79', 'L1_82', 'L0_1...</td>\n",
       "      <td>BPC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               segment_id  split_index  nucleus_id external_layer  \\\n",
       "115    864691134884748026            0      366181        LAYER_5   \n",
       "147    864691134884761338            0      458241        LAYER_4   \n",
       "170    864691134884769786            0      592718        LAYER_5   \n",
       "205    864691134884879610            0      304873        LAYER_5   \n",
       "213    864691134884945146            0       63499      LAYER_2/3   \n",
       "...                   ...          ...         ...            ...   \n",
       "60416  864691137197239105            0      262000        LAYER_4   \n",
       "60417  864691137197241665            0      308938        LAYER_6   \n",
       "60433  864691137197306177            0      304611        LAYER_5   \n",
       "60442  864691137197321281            0      434601        LAYER_5   \n",
       "60445  864691137197329985            0      260468        LAYER_4   \n",
       "\n",
       "      external_visual_area                                     cell_type_fine  \\\n",
       "115                     V1  [{'nodelist': ['L0_10', 'L0_11', 'L0_12', 'L0_...   \n",
       "147                     RL  [{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_3',...   \n",
       "170                     RL  [{'nodelist': ['L0_18', 'L0_11', 'L0_17', 'L0_...   \n",
       "205                     V1  [{'nodelist': ['L2_4', 'L1_1', 'L0_3', 'L1_6',...   \n",
       "213                     V1  [{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_3',...   \n",
       "...                    ...                                                ...   \n",
       "60416                   V1  [{'nodelist': ['L0_0', 'L0_1', 'L0_2', 'L0_3',...   \n",
       "60417                   V1  [{'nodelist': ['L1_4', 'L0_18', 'L4_1', 'L0_16...   \n",
       "60433                   V1  [{'nodelist': ['L0_1', 'L0_3', 'L0_6', 'L0_0',...   \n",
       "60442                   RL  [{'nodelist': ['L0_3', 'L3_3', 'L2_2', 'L2_3',...   \n",
       "60445                   V1  [{'nodelist': ['L0_3', 'L1_79', 'L1_82', 'L0_1...   \n",
       "\n",
       "      cell_type_fine_label  \n",
       "115                     4P  \n",
       "147                    23P  \n",
       "170                  5P_IT  \n",
       "205               IT_short  \n",
       "213                    23P  \n",
       "...                    ...  \n",
       "60416                   4P  \n",
       "60417               Unsure  \n",
       "60433                5P_NP  \n",
       "60442                   6P  \n",
       "60445                  BPC  \n",
       "\n",
       "[3338 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.query(\"cell_type_fine_label == cell_type_fine_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodelist': array(['L0_1', 'L0_0', 'L0_2'], dtype=object),\n",
       " 'features': array(['mesh_volume', 'n_spines', 'n_synapses_head', 'n_synapses_neck',\n",
       "        'n_synapses_post', 'n_synapses_pre', 'skeletal_length',\n",
       "        'total_spine_volume', 'width_upstream', 'width_downstream',\n",
       "        'apical_label', 'basal_label', 'skeleton_vector_downstream_phi',\n",
       "        'skeleton_vector_downstream_theta', 'skeleton_vector_upstream_phi',\n",
       "        'skeleton_vector_upstream_theta', 'width_no_spine'], dtype=object),\n",
       " 'adjacency': array([[0, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]),\n",
       " 'feature_matrix': array([[ 3.71170715e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.43345470e+03,  0.00000000e+00,  5.91837642e+01,\n",
       "          5.91837642e+01,  0.00000000e+00,  1.00000000e+00,\n",
       "         -6.22637047e-01,  2.00297982e+00, -6.22637047e-01,\n",
       "          2.00297982e+00,  5.91837642e+01],\n",
       "        [ 2.99289539e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          6.76722467e+03,  0.00000000e+00,  4.71136497e+02,\n",
       "          8.69454592e+02,  0.00000000e+00,  1.00000000e+00,\n",
       "          3.01881171e+00,  1.61006762e+00, -2.79826200e+00,\n",
       "          2.06957198e+00,  7.32983276e+02],\n",
       "        [ 8.07215086e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          4.79074407e+03,  0.00000000e+00,  1.97902300e+02,\n",
       "          4.48326427e+02,  0.00000000e+00,  1.00000000e+00,\n",
       "          1.19580679e+00,  7.15696534e-01,  1.01784622e+00,\n",
       "          7.42017670e-01,  3.82383945e+02]]),\n",
       " 'label_name': None,\n",
       " 'graph_label': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = data_df[[\"cell_type_fine\"]].iloc[1].to_list()[0][0]\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Creating the Pytorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- a) Getting Means and Std Dev for Normalization --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mesh_volume                         1.0\n",
       "n_spines                            1.0\n",
       "n_synapses_head                     1.0\n",
       "n_synapses_neck                     1.0\n",
       "n_synapses_post                     1.0\n",
       "n_synapses_pre                      1.0\n",
       "skeletal_length                     1.0\n",
       "total_spine_volume                  1.0\n",
       "width_upstream                      1.0\n",
       "width_downstream                    1.0\n",
       "apical_label                        1.0\n",
       "basal_label                         1.0\n",
       "skeleton_vector_downstream_phi      1.0\n",
       "skeleton_vector_downstream_theta    1.0\n",
       "skeleton_vector_upstream_phi        1.0\n",
       "skeleton_vector_upstream_theta      1.0\n",
       "width_no_spine                      1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_batch_df = pd.concat([nxio.feature_df_from_gnn_info(\n",
    "    k[0],\n",
    "    return_data_labels_split = False) for k in data_df[gnn_task].to_list()])\n",
    "\n",
    "if label_name is not None:\n",
    "    all_batch_df = all_batch_df[[k for k in \n",
    "            all_batch_df.columns if k not in nu.convert_to_array_like(label_name)]]\n",
    "else:\n",
    "    all_batch_df = all_batch_df\n",
    "    \n",
    "# will use these to normalize the data\n",
    "col_means = all_batch_df.mean(axis=0).to_numpy()\n",
    "col_stds = all_batch_df.std(axis=0).to_numpy()\n",
    "\n",
    "all_batch_df_norm = pu.normalize_df(all_batch_df,column_means=col_means,\n",
    "                                 column_stds = col_stds)\n",
    "all_batch_df_norm.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- b) Creating the Dataset Class --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1P': 1,\n",
       " '23P': 2,\n",
       " '4P': 3,\n",
       " '5P_IT': 4,\n",
       " '5P_NP': 5,\n",
       " '5P_PT': 6,\n",
       " '6CT': 7,\n",
       " '6P': 8,\n",
       " '6P_CT': 9,\n",
       " '6P_IT': 10,\n",
       " '6P_U': 11,\n",
       " 'BC': 12,\n",
       " 'BPC': 13,\n",
       " 'I targeting non_bpc': 14,\n",
       " 'IT_big_tuft': 15,\n",
       " 'IT_short': 16,\n",
       " 'IT_small_tuft': 17,\n",
       " 'Martinotti': 18,\n",
       " 'NGC': 19,\n",
       " 'Pvalb': 20,\n",
       " 'SST': 21,\n",
       " 'Unsure': 22,\n",
       " 'VIP': 23,\n",
       " 'WM_P': 24,\n",
       " 'cb1 basket': 25,\n",
       " 'chandelier': 26,\n",
       " 'l1vip': 27,\n",
       " 'ndnf+npy_': 28,\n",
       " 'ngfc': 29,\n",
       " 'prox targeting': 30,\n",
       " 'small basket': 31,\n",
       " None: 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- mapping of the labels to integers --\n",
    "total_labels,label_counts = np.unique((data_df.query(f\"{graph_label}=={graph_label}\")[\n",
    "    graph_label]).to_numpy(),return_counts = True)\n",
    "cell_type_map = {k:i+1 for i,k in enumerate(total_labels)}\n",
    "cell_type_map[None] = 0\n",
    "cell_type_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 1.  , 0.25, 0.3 , 0.5 , 1.  , 0.8 , 1.  , 0.8 , 1.  , 0.8 ,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell_type_map\n",
    "cell_type_fine_classifier_weights = {\n",
    "'23P': 0.25,#1294\n",
    "'4P': 0.3,#890\n",
    "'5P_IT': 0.5,#465\n",
    "'6P': 0.8,#342\n",
    "'6P_IT': 0.8,#263\n",
    "'5P_PT': 0.8,#224\n",
    "}\n",
    "\n",
    "\n",
    "class_idx = np.array(list(cell_type_map.values()) )\n",
    "class_labels = np.array(list(cell_type_map.keys()) )\n",
    "weights = np.array([cell_type_fine_classifier_weights.get(k,1) for k in class_labels])\n",
    "weights = weights[np.argsort(class_idx)]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_data_from_gnn_info(\n",
    "    gnn_info,\n",
    "    y = None,\n",
    "    verbose = False,\n",
    "    normalize = True,\n",
    "    features_to_delete=None,\n",
    "    features_to_keep = None\n",
    "    ): \n",
    "    \"\"\"\n",
    "    Purpose: To convert our data format into pytorch Data object\n",
    "\n",
    "    Pseudocode: \n",
    "    1) Create the edgelist (turn into tensor)\n",
    "    2) Get the \n",
    "    \"\"\"\n",
    "    edgelist = torch.tensor(xu.edgelist_from_adjacency_matrix(\n",
    "        array = gnn_info[\"adjacency\"],\n",
    "        verbose = False,\n",
    "    ).T,dtype=torch.long)\n",
    "\n",
    "    x,y_raw = nxio.feature_df_from_gnn_info(\n",
    "        gnn_info,\n",
    "        return_data_labels_split = True)\n",
    "    if y is None:\n",
    "        y = y_raw\n",
    "        \n",
    "    if not type(y) == str:\n",
    "        y = None\n",
    "        \n",
    "    y_int = np.array(cell_type_map[y] ).reshape(1,-1)\n",
    "    \n",
    "    if normalize:\n",
    "        x = (x-col_means)/col_stds\n",
    "    \n",
    "    # --- keeping or not keeping sertain features\n",
    "    gnn_features = gnn_info[\"features\"]\n",
    "\n",
    "    keep_idx = np.arange(len(gnn_features))\n",
    "    if features_to_delete is not None:\n",
    "        curr_idx = np.array([i for i,k in enumerate(gnn_features)\n",
    "                       if k not in features_to_delete])\n",
    "        keep_idx = np.intersect1d(keep_idx,curr_idx)\n",
    "        if verbose:\n",
    "            print(f\"keep_idx AFTER DELETE= {keep_idx}\")\n",
    "    if features_to_keep is not None:\n",
    "        curr_idx = np.array([i for i,k in enumerate(gnn_features)\n",
    "                       if k in features_to_keep])\n",
    "        keep_idx = np.intersect1d(keep_idx,curr_idx)\n",
    "        if verbose:\n",
    "            print(f\"keep_idx AFTER KEEP = {keep_idx}\")\n",
    "\n",
    "    x = x[:,keep_idx]\n",
    "\n",
    "    x = torch.tensor(x,dtype=torch.float)\n",
    "    y = torch.tensor(y_int,dtype=torch.long)\n",
    "    \n",
    "    if len(y) > 1:\n",
    "        raise Exception(f\"y = {y}\")\n",
    "        \n",
    "    if y.shape[0] != 1 or y.shape[1] != 1:\n",
    "        raise Exception(f\"y = {y}\")\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"x.shape = {x.shape},y.shape ={y.shape}\")\n",
    "\n",
    "    data = Data(x=x,y=y,edge_index=edgelist)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellTypeDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        #return ['some_file_1', 'some_file_2', ...]\n",
    "        return [str(data_filepath.absolute())]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    # def download(self):\n",
    "    #     # Download to `self.raw_dir`.\n",
    "    #     download_url(url, self.raw_dir)\n",
    "    #     ...\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        #data_list = [...]\n",
    "\n",
    "#         if data_df is None:\n",
    "#             data_df = su.decompress_pickle(self.raw_file_names[0])\n",
    "\n",
    "        \n",
    "        \n",
    "        data_list = []\n",
    "        for k,y in tqdm(zip(\n",
    "            data_df[gnn_task].to_list(),\n",
    "            data_df[graph_label].to_list())):\n",
    "            \n",
    "            data_list.append(pytorch_data_from_gnn_info(\n",
    "                k[0],\n",
    "                y=y,\n",
    "                features_to_delete=features_to_delete,\n",
    "                features_to_keep = features_to_keep,\n",
    "                verbose = False))\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list_final = []\n",
    "            for data in data_list:\n",
    "                try:\n",
    "                    if self.pre_filter(data):\n",
    "                        data_list_final.append(data)\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            data_list = data_list_final\n",
    "            \n",
    "        for j,d in enumerate(data_list):\n",
    "            if d.y.shape[0] != 1 or d.y.shape[1] != 1:\n",
    "                raise Exception(f\"{j}\")\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list_final = []\n",
    "            for j,data in enumerate(data_list):\n",
    "                try:\n",
    "                    curr_t = self.pre_transform(data)\n",
    "                    if curr_t.y.shape[0] != 1 or curr_t.y.shape[1] != 1:\n",
    "                        raise Exception(f\"{j}, data = {curr_t}\")\n",
    "                    data_list_final.append(curr_t)\n",
    "                except:\n",
    "                    continue\n",
    "            data_list = data_list_final\n",
    "            \n",
    "        for j,d in enumerate(data_list):\n",
    "            if d.y.shape[0] != 1 or d.y.shape[1] != 1:\n",
    "                raise Exception(f\"{j}, data = {d}\")\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if with_skeleton:\n",
    "    gnn_task_name = f\"{gnn_task}_with_skeleton\"\n",
    "else:\n",
    "    gnn_task_name = f\"{gnn_task}\"\n",
    "\n",
    "if dense_adj:\n",
    "    processed_data_folder = data_path / Path(f\"{gnn_task_name}\")#_processed_dense\")\n",
    "elif directed:\n",
    "    processed_data_folder = data_path / Path(f\"{gnn_task_name}_directed\")#_processed_dense\")\n",
    "else:\n",
    "    processed_data_folder = data_path / Path(f\"{gnn_task_name}_no_dense\")#_processed_dense\")\n",
    "    \n",
    "# try:\n",
    "#     su.rm_dir(processed_data_folder)\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "processed_data_folder.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724536d8f59c44fd83b9cf912dbb0aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "max_nodes = np.max(all_batch_df_norm.index.to_numpy()) + 1\n",
    "\n",
    "class MyFilter(object):\n",
    "    def __call__(self, data):\n",
    "        return data.num_nodes <= max_nodes\n",
    "    \n",
    "if dense_adj:\n",
    "    #gets the maximum number of nodes in any of the graphs\n",
    "    transform_list = [\n",
    "        transforms.ToUndirected(),\n",
    "        T.ToDense(max_nodes),\n",
    "        #transforms.NormalizeFeatures(),\n",
    "    ]\n",
    "    pre_filter = MyFilter()\n",
    "elif directed:\n",
    "    transform_list = []\n",
    "    pre_filter = None\n",
    "else:\n",
    "    transform_list = [\n",
    "        transforms.ToUndirected(),\n",
    "    ]\n",
    "    \n",
    "    pre_filter = None\n",
    "    \n",
    "\n",
    "transform_norm = transforms.Compose(transform_list)\n",
    "dataset = CellTypeDataset(\n",
    "        processed_data_folder.absolute(),\n",
    "        pre_transform = transform_norm,\n",
    "        pre_filter = pre_filter,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,d in enumerate(dataset):\n",
    "    if d.y.shape[0] != 1 or d.y.shape[1] != 1:\n",
    "        raise Exception(f\"{j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num_node_features = dataset.num_node_features\n",
    "dataset_num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: CellTypeDataset(58948):\n",
      "====================\n",
      "Number of graphs: 58948\n",
      "Number of features: 14\n",
      "Number of classes: 32\n",
      "\n",
      "Data(x=[3, 14], edge_index=[2, 4], y=[1, 1])\n",
      "=============================================================\n",
      "Number of nodes: 3\n",
      "Number of edges: 4\n",
      "Average node degree: 1.33\n"
     ]
    }
   ],
   "source": [
    "# looking at the dataset\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset_num_node_features}')\n",
    "print(f'Number of classes: {dataset_num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "# print(f'Has self-loops: {data.has_self_loops()}')\n",
    "# print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- c) Splitting the Data into Labeled and unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3338"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_mask = np.array(\n",
    "    [True if k.y[0][0] > 0 else False for k in dataset]\n",
    ").astype('int')\n",
    "dataset_labeled = dataset[np.where(labeled_mask)[0]]\n",
    "len(dataset_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_curr = dataset_labeled\n",
    "torch.manual_seed(12345)\n",
    "dataset_curr = dataset_curr.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- d) Split Train/Validation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To turn percentages into raw lengths\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To turn percentages into raw lengths\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size = 667.0 (0.2 %)\n",
      "validation size = 667.0 (0.2 %)\n",
      "train_size = 2004.0\n",
      "data_lengths_with_train = [2004  667  667]\n",
      "Number of training graphs: 2004\n",
      "Number of test graphs: 667\n",
      "Number of val graphs: 667\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "(train_dataset,\n",
    "val_dataset,\n",
    "test_dataset,) = pret.train_val_test_split(\n",
    "    dataset_curr,\n",
    "    return_dict=False,\n",
    "    verbose = True)\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "print(f'Number of val graphs: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if wanted to try and add weights\n",
    "# y_train = np.array([int(data.y[0][0].numpy()) for data in train_dataset])\n",
    "# y_train_classes,y_train_count = np.unique(y_train,return_counts = True)\n",
    "# y_train_classes,y_train_count\n",
    "\n",
    "# sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
    "\n",
    "# weight = {i:1/}\n",
    "# samples_weight = np.array([weight[t] for t in y_train])\n",
    "# samples_weight = torch.from_numpy(samples_weight)\n",
    "# samples_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dense_adj:\n",
    "    data_loader_mod = DenseDataLoader\n",
    "else:\n",
    "    data_loader_mod = DataLoader\n",
    "\n",
    "\n",
    "train_loader = data_loader_mod(train_dataset, batch_size=batch_size,shuffle = True)\n",
    "test_loader = data_loader_mod(test_dataset, batch_size=batch_size,shuffle=False)\n",
    "val_loader = data_loader_mod(val_dataset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3a; Picking the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"GCNFlat\"\n",
    "n_epochs = 100\n",
    "\n",
    "\n",
    "import general_utils as gu\n",
    "architecture_kwargs_global = dict(\n",
    "    n_hidden_channels = 32, \n",
    "    #n_hidden_channels=64, \n",
    "    #first_heads=8, \n",
    "    #output_heads=1, \n",
    "    #dropout=0.6,\n",
    "    global_pool_type=\"mean\",\n",
    "    n_layers = 2\n",
    ")\n",
    "\n",
    "optimizer_kwargs_global = dict(\n",
    "    lr=0.01\n",
    ")\n",
    "\n",
    "all_run_kwargs = [\n",
    "     dict(architecture_kwargs = {'n_hidden_channels': 64, 'global_pool_type': 'mean', 'n_layers': 2,\n",
    "                                # \"use_bn\":False, \"n_hidden_layers_classifier\": 0\n",
    "                                }\n",
    "         ),\n",
    "#     dict(architecture_kwargs = dict(n_hidden_channels = 64),),\n",
    "#     dict(architecture_kwargs = dict(n_hidden_channels = 128),),\n",
    "#     dict(architecture_kwargs = dict(n_layers = 1,n_hidden_channels = 64),),\n",
    "#     dict(architecture_kwargs = dict(n_layers = 1,n_hidden_channels = 128),),\n",
    "    \n",
    "    \n",
    "#     dict(architecture_kwargs = dict(n_hidden_channels = 32,global_pool_type=\"add\"),),\n",
    "#     dict(architecture_kwargs = dict(n_hidden_channels = 16,global_pool_type=\"add\"),),\n",
    "#     dict(architecture_kwargs = dict(n_hidden_channels = 8,global_pool_type=\"add\"),),\n",
    "#     dict(architecture_kwargs = dict(n_layers = 1,n_hidden_channels = 32,global_pool_type=\"add\"),),\n",
    "#     dict(architecture_kwargs = dict(n_layers = 1,n_hidden_channels = 16,global_pool_type=\"add\"),),\n",
    "#     dict(architecture_kwargs = dict(n_layers = 1,n_hidden_channels = 8,global_pool_type=\"add\"),),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation_utils as evu\n",
    "import torch.nn.functional as F\n",
    "import model_utils as mdlu\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****------ Running Model Config 0 with following parameters ------****\n",
      "{'n_hidden_channels': 64, 'global_pool_type': 'mean', 'n_layers': 2, 'lr': 0.01}\n",
      "GCNFlat(\n",
      "  (conv0): GCNConv(14, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=32, bias=True)\n",
      ")\n",
      "tensorboard_file_name = GCNFlat_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True\n",
      "GCNFlat(\n",
      "  (conv0): GCNConv(14, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=32, bias=True)\n",
      ")\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [3 4 8],y_pred_counts = [1983   19    2]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [3 4],y_pred_counts = [663   4]\n",
      "Epoch: 000, loss = 3.4929895401000977\n",
      "   train metrics:  accuracy: 0.229042,\n",
      "   val metrics:  accuracy: 0.209895,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [3 4 8],y_pred_counts = [1862   54   88]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [3 4 8],y_pred_counts = [615  20  32]\n",
      "Epoch: 001, loss = 3.3120691776275635\n",
      "   train metrics:  accuracy: 0.243513,\n",
      "   val metrics:  accuracy: 0.221889,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [ 3  8 13],y_pred_counts = [1188  815    1]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [3 8],y_pred_counts = [381 286]\n",
      "Epoch: 002, loss = 3.240593671798706\n",
      "   train metrics:  accuracy: 0.251497,\n",
      "   val metrics:  accuracy: 0.229385,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [2 3 8],y_pred_counts = [  15 1058  931]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [2 3 8],y_pred_counts = [  3 347 317]\n",
      "Epoch: 003, loss = 3.052985668182373\n",
      "   train metrics:  accuracy: 0.249002,\n",
      "   val metrics:  accuracy: 0.226387,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [2 3 8],y_pred_counts = [627 843 534]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [2 3 8],y_pred_counts = [222 269 176]\n",
      "Epoch: 004, loss = 2.8615026473999023\n",
      "   train metrics:  accuracy: 0.343313,\n",
      "   val metrics:  accuracy: 0.331334,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [1748  256]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [601  66]\n",
      "Saving off checkpoint model_checkpoints/GCNFlat/GCNFlat_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True_checkpoints/GCNFlat_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True_epoch_5\n",
      "Epoch: 005, loss = 2.8814849853515625\n",
      "   train metrics:  accuracy: 0.296906,\n",
      "   val metrics:  accuracy: 0.316342,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [1807  197]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [614  53]\n",
      "Epoch: 006, loss = 2.8667752742767334\n",
      "   train metrics:  accuracy: 0.298403,\n",
      "   val metrics:  accuracy: 0.317841,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [1881  123]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [628  39]\n",
      "Epoch: 007, loss = 2.8324365615844727\n",
      "   train metrics:  accuracy: 0.293912,\n",
      "   val metrics:  accuracy: 0.316342,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [1799  205]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [611  56]\n",
      "Epoch: 008, loss = 2.480379819869995\n",
      "   train metrics:  accuracy: 0.301397,\n",
      "   val metrics:  accuracy: 0.322339,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [ 2  3  4 12],y_pred_counts = [1660  342    1    1]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [2 3],y_pred_counts = [564 103]\n",
      "Epoch: 009, loss = 2.8335790634155273\n",
      "   train metrics:  accuracy: 0.305389,\n",
      "   val metrics:  accuracy: 0.328336,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [ 2  3  4  6  8 12],y_pred_counts = [1191  504   49    7  206   47]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [ 2  3  4  6  8  9 12],y_pred_counts = [405 152  26   3  63   3  15]\n",
      "Saving off checkpoint model_checkpoints/GCNFlat/GCNFlat_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True_checkpoints/GCNFlat_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True_epoch_10\n",
      "Epoch: 010, loss = 2.7266695499420166\n",
      "   train metrics:  accuracy: 0.358283,\n",
      "   val metrics:  accuracy: 0.355322,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [ 2  3  4  5  6  8  9 10 12],y_pred_counts = [600 600  12   3 205 389   1 101  93]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [ 2  3  4  6  8 10 12],y_pred_counts = [217 181   2  77 126  30  34]\n",
      "Epoch: 011, loss = 2.4562950134277344\n",
      "   train metrics:  accuracy: 0.403194,\n",
      "   val metrics:  accuracy: 0.413793,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [ 2  3  5  6  8 10 12 18],y_pred_counts = [123 588  12 301 511 352  82  35]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [ 2  3  5  6  8 10 12 18],y_pred_counts = [ 35 196   4 107 176 106  32  11]\n",
      "Epoch: 012, loss = 2.3566019535064697\n",
      "   train metrics:  accuracy: 0.324351,\n",
      "   val metrics:  accuracy: 0.313343,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [ 2  3  5  6  8 10 12 13 18],y_pred_counts = [  4 401  20 227 622 584  49   4  93]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [ 2  3  5  6  8 10 12 13 18],y_pred_counts = [  2 130   5  79 206 192  20   1  32]\n",
      "Epoch: 013, loss = 2.3555386066436768\n",
      "   train metrics:  accuracy: 0.264471,\n",
      "   val metrics:  accuracy: 0.253373,\n",
      "   y_true_unique= [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 26 27 28 29 30 31],y_true_counts = [ 10 564 457 222  46  76  15 149  67 128  10  44  36   9  16  18  22  47\n",
      "   5   2  20  14   3   8   1   2   6   5   1   1]\n",
      "   y_pred_unique= [ 3  5  6  8 10 12 13 18],y_pred_counts = [322  16 118 881 498  26   9 134]\n",
      "   y_true_unique= [ 1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 28 29],y_true_counts = [  1 204 140  75  11  33  47  22  35   4  17  15   1   8  10   4  13   5\n",
      "   2   7   4   2   3   2   1   1]\n",
      "   y_pred_unique= [ 3  5  6  8 10 12 13 18],y_pred_counts = [ 98   4  38 296 169  14   5  43]\n",
      "Epoch: 014, loss = 2.4601142406463623\n",
      "   train metrics:  accuracy: 0.241018,\n",
      "   val metrics:  accuracy: 0.229385,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-dcebd953f0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# new line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mtrain_metric_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#train_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mval_metric_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-dcebd953f0e6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader, verbose)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0my_pred_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0my_true_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate in batches over the training/test dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DiffPool\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_geometric/loader/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0;32m---> 20\u001b[0;31m                                         self.exclude_keys)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0madd_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mfollow_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mexclude_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         )\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# Collate attributes into a unified representation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             value, slices, incs = _collate(attr, values, data_list, stores,\n\u001b[0;32m---> 86\u001b[0;31m                                            increment)\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_dim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_incs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mget_incs\u001b[0;34m(key, values, data_list, stores)\u001b[0m\n\u001b[1;32m    220\u001b[0m     repeats = [\n\u001b[1;32m    221\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     ]\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m     repeats = [\n\u001b[1;32m    221\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     ]\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j,config_dict in enumerate(all_run_kwargs):\n",
    "    \n",
    "    architecture_kwargs = config_dict.get(\"architecture_kwargs\",dict())\n",
    "    optimizer_kwargs = config_dict.get(\"optimizer_kwargs\",dict())\n",
    "    \n",
    "    architecture_kwargs = gu.merge_dicts([architecture_kwargs_global.copy(),architecture_kwargs])\n",
    "    optimizer_kwargs = gu.merge_dicts([optimizer_kwargs_global.copy(),optimizer_kwargs])\n",
    "    \n",
    "    run_kwargs = gu.merge_dicts([architecture_kwargs,optimizer_kwargs])\n",
    "\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n\\n\\n****------ Running Model Config {j} with following parameters ------****\\n{run_kwargs}\")\n",
    "\n",
    "    model = getattr(gm,model_name)(\n",
    "        dataset_num_node_features=dataset_num_node_features,\n",
    "        dataset_num_classes=dataset_num_classes,\n",
    "        **architecture_kwargs\n",
    "        )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), **optimizer_kwargs)\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    \n",
    "    # ---------------- Configuring the Tensorboard and Checkpoinns--------------------\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "    tensorboard_dir = Path(\"./tensorboard\")\n",
    "    tensorboard_dir.mkdir(exist_ok=True)\n",
    "    tensorboard_dir = tensorboard_dir / Path(f\"{model_name}\")\n",
    "    tensorboard_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    tensorboard_file_name = (f'{model_name}_' \n",
    "                             + \"_\".join([f\"{k}_{v}\" for k,v in run_kwargs.items()]))\n",
    "    tensorboard_file_name += f\"_with_skeleton_{with_skeleton}\"\n",
    "    print(f\"tensorboard_file_name = {tensorboard_file_name}\")\n",
    "    tensorboard_file = tensorboard_dir / Path(f'{tensorboard_file_name}')\n",
    "    try:\n",
    "        su.rm_dir(tensorboard_file)\n",
    "    except:\n",
    "        pass\n",
    "    tensorboard_file.mkdir(exist_ok = True)\n",
    "\n",
    "\n",
    "    #-- when to save a checkpoint of the model\n",
    "    checkpoint_dir = Path(\"./model_checkpoints\")\n",
    "    checkpoint_dir.mkdir(exist_ok = True)\n",
    "    checkpoint_dir = checkpoint_dir / Path(f\"{model_name}\")\n",
    "    checkpoint_dir.mkdir(exist_ok = True)\n",
    "    checkpoint_path = checkpoint_dir / Path(f\"./{tensorboard_file_name}_checkpoints\")\n",
    "\n",
    "    try:\n",
    "        su.rm_dir(checkpoint_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    checkpoint_path.mkdir(exist_ok = True)\n",
    "    n_epoch_for_checkpoint = 5\n",
    "\n",
    "    writer = SummaryWriter(tensorboard_file)\n",
    "    \n",
    "\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    # weights = weight#[0.1,0.5,,1,0.7,1,1,1]\n",
    "    # class_weights = None\n",
    "    class_weights = torch.FloatTensor(weights).to(device)\n",
    "\n",
    "    tensor_map = None\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "\n",
    "        for data in train_loader:#train_loader:  # Iterate in batches over the training dataset.\n",
    "            #print(f\"data = {data}\")\n",
    "            data = data.to(device)\n",
    "            if model_name == \"DiffPool\":\n",
    "                out,gnn_loss, cluster_loss = model(data)  # Perform a single forward pass.\n",
    "                #y_true = data.y.reshape(-1,3)\n",
    "            elif model_name == \"TreeLSTM\":\n",
    "                n = data.x.shape[0]\n",
    "                h = torch.zeros((n, architecture_kwargs[\"n_hidden_channels\"]))\n",
    "                c = torch.zeros((n, architecture_kwargs[\"n_hidden_channels\"]))\n",
    "                out = model(\n",
    "                    data,\n",
    "                    h = h,\n",
    "                    c = c,\n",
    "                    embeddings = data.x\n",
    "                    )\n",
    "            else:\n",
    "                out = model(data)\n",
    "            y_true = data.y.squeeze_()\n",
    "            #print(f\"out.shape = {out.shape}, data.y.shape = {data.y.shape}\")\n",
    "            loss = F.nll_loss(\n",
    "                torch.log(out), y_true,\n",
    "                weight = class_weights,\n",
    "            )  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "            return loss\n",
    "\n",
    "\n",
    "    def test(loader,verbose = False):\n",
    "        model.eval()\n",
    "        y_pred_list = []\n",
    "        y_true_list = []\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            data = data.to(device)\n",
    "            if model_name == \"DiffPool\":\n",
    "                out,gnn_loss, cluster_loss = model(data)  # Perform a single forward pass.\n",
    "                #y_true = data.y.reshape(-1,3)\n",
    "            elif model_name == \"TreeLSTM\":\n",
    "                n = data.x.shape[0]\n",
    "                h = torch.zeros((n, architecture_kwargs[\"n_hidden_channels\"]))\n",
    "                c = torch.zeros((n, architecture_kwargs[\"n_hidden_channels\"]))\n",
    "                out = model(\n",
    "                    data,\n",
    "                    h = h,\n",
    "                    c = c,\n",
    "                    embeddings = data.x\n",
    "                    )\n",
    "            else:\n",
    "                out = model(data)\n",
    "\n",
    "            y_pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            y_true = data.y.squeeze_()\n",
    "            y_pred_list.append(y_pred)\n",
    "            y_true_list.append(y_true)\n",
    "    #         error_idx = np.where(pred > 0)[0]\n",
    "    #         if len(error_idx) > 0:\n",
    "    #             print(f\"error_idx = {error_idx}\")\n",
    "        y_pred = torch.cat(y_pred_list)\n",
    "        y_true = torch.cat(y_true_list)\n",
    "\n",
    "        return evu.metric_dict(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            tensor_map=tensor_map,\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "    log_to_tensorboard = True\n",
    "    for epoch in range(0, n_epochs):\n",
    "        loss = train()\n",
    "        writer.add_scalar('loss',loss,epoch) # new line\n",
    "        train_metric_dict = test(train_loader)#train_loader)\n",
    "        val_metric_dict = test(val_loader)#test_loader)\n",
    "\n",
    "        if epoch % n_epoch_for_checkpoint == 0 and epoch != 0:\n",
    "            val_acc = val_metric_dict['accuracy'].numpy()\n",
    "            checkpoitn_filepath = checkpoint_path / Path(f\"{tensorboard_file_name}_epoch_{epoch}\")#_val_acc_{val_acc:.2f}\")\n",
    "            print(f\"Saving off checkpoint {checkpoitn_filepath}\")\n",
    "            mdlu.save_checkpoint(model,filepath = checkpoitn_filepath,epoch = epoch,loss = loss)\n",
    "\n",
    "\n",
    "        print(f'Epoch: {epoch:03d}, loss = {loss}')\n",
    "        for type_name,metric_dict in zip([\"train\",\"val\"],[train_metric_dict,val_metric_dict]):\n",
    "            print_log = f\"   {type_name} metrics: \"\n",
    "            for k,v in metric_dict.items():\n",
    "                if log_to_tensorboard:\n",
    "                    writer.add_scalar(f'{type_name}_{k}',v,epoch)\n",
    "                print_log += f\" {k}: {v:4f},\"\n",
    "\n",
    "            print(print_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Picking the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-10ec4cded28c666e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-10ec4cded28c666e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /pytorch_tools/Applications/Cell_Types_GNN/tensorboard --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard.backend.event_processing.event_file_loader as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventFileLoader',\n",
       " 'LegacyEventFileLoader',\n",
       " 'RawEventFileLoader',\n",
       " 'TimestampedEventFileLoader',\n",
       " '_NULLCONTEXT',\n",
       " '_PyRecordReaderIterator',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_make_tf_record_iterator',\n",
       " '_nullcontext',\n",
       " '_silence_deprecation_warnings',\n",
       " 'contextlib',\n",
       " 'data_compat',\n",
       " 'dataclass_compat',\n",
       " 'event_pb2',\n",
       " 'logger',\n",
       " 'platform_util',\n",
       " 'tb_logging',\n",
       " 'tf']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---working on ./tensorboard/DiffPooln_hidden_channels_32/events.out.tfevents.1651525078.at-node20.31131.0---\n",
      "---working on ./tensorboard/DiffPooln_hidden_channels_32/events.out.tfevents.1651524415.at-node20.31039.0---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_32_cell_type_childsum/events.out.tfevents.1651574324.at-node20.10618.24---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_32_cell_type_childsum/events.out.tfevents.1651574271.at-node20.10618.23---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_32_cell_type_childsum/events.out.tfevents.1651573733.at-node20.10618.20---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_32_cell_type_childsum/events.out.tfevents.1651574167.at-node20.10618.22---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_32_cell_type_childsum/events.out.tfevents.1651574124.at-node20.10618.21---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651532008.at-node20.3250.8---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651531528.at-node20.3250.5---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651531675.at-node20.3250.6---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651530462.at-node20.3250.1---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651530468.at-node20.3250.2---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651532267.at-node20.3250.9---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651530538.at-node20.3250.4---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651531985.at-node20.3250.7---\n",
      "---working on ./tensorboard/DiffPoolSAGE_n_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651530499.at-node20.3250.3---\n",
      "---working on ./tensorboard/GCNFlat/GCNFlat_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True/events.out.tfevents.1651663537.at-node20.771.1---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_8/events.out.tfevents.1651563221.at-node20.10618.0---\n",
      "---working on ./tensorboard/DiffPoolSAGEn_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651530445.at-node20.3250.0---\n",
      "---working on ./tensorboard/DiffPooln_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651530111.at-node20.1337.3---\n",
      "---working on ./tensorboard/DiffPooln_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651529997.at-node20.1337.1---\n",
      "---working on ./tensorboard/DiffPooln_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651530036.at-node20.1337.2---\n",
      "---working on ./tensorboard/DiffPooln_hidden_channels_32_n_pool_layers_4_max_nodes_300/events.out.tfevents.1651529958.at-node20.1337.0---\n",
      "---working on ./tensorboard/DiffPooln_hidden_channels_8_n_pool_layers_4_max_nodes_221/events.out.tfevents.1651554989.at-node20.9758.0---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651563759.at-node20.10618.3---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651566611.at-node20.10618.11---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651566469.at-node20.10618.9---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651567812.at-node20.10618.13---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651565088.at-node20.10618.7---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651566525.at-node20.10618.10---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651563695.at-node20.10618.2---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651568502.at-node20.10618.14---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651563557.at-node20.10618.1---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651563925.at-node20.10618.6---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651565377.at-node20.10618.8---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651567546.at-node20.10618.12---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651568717.at-node20.10618.15---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651563777.at-node20.10618.4---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651569067.at-node20.10618.16---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12/events.out.tfevents.1651563914.at-node20.10618.5---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12_cell_type_childsum/events.out.tfevents.1651573147.at-node20.10618.19---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12_cell_type_childsum/events.out.tfevents.1651573044.at-node20.10618.18---\n",
      "---working on ./tensorboard/TreeLSTMn_hidden_channels_12_cell_type_childsum/events.out.tfevents.1651569150.at-node20.10618.17---\n"
     ]
    }
   ],
   "source": [
    "# from tensorboard.backend.event_processing.event_file_loader import EventFileLoader\n",
    "# import tensorboard_utils as tbu\n",
    "# df_board = tbu.df_tensorboard(\"./tensorboard/\",verbose = True)\n",
    "# #df_board.query(\"(run=='DiffPooln_hidden_channels_32') and (name=='train_accuracy')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_name = \"GCNFlat_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True\"\n",
    "epoch = 95\n",
    "winning_dir = checkpoint_dir / Path(f\"{winning_name}_checkpoints\") \n",
    "winning_filepath = winning_dir / Path(f\"{winning_name}_epoch_{epoch}\")\n",
    "winning_filepath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN_n_hidden_channels_64_global_pool_type_mean_n_layers_2_lr_0.01_with_skeleton_True_epoch_95 #good one for seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Running Embedding for all cell types (Can Run in Batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_kwargs_curr = dict(n_hidden_channels = 64,global_pool_type = \"mean\",n_layers = 2)\n",
    "architecture_kwargs = gu.merge_dicts([architecture_kwargs_global,architecture_kwargs_curr])\n",
    "architecture_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getattr(gm,model_name)(\n",
    "    dataset_num_node_features=dataset_num_node_features,\n",
    "    dataset_num_classes=dataset_num_classes,\n",
    "    **architecture_kwargs,\n",
    "    #use_bn=False\n",
    "    )\n",
    "\n",
    "checkpoint = torch.load(winning_filepath)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_loader = data_loader_mod(dataset, batch_size=batch_size,shuffle = False)\n",
    "all_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "embeddings = []\n",
    "labels = []\n",
    "for data in tqdm(all_data_loader):#train_loader:  # Iterate in batches over the training dataset.\n",
    "    data = data.to(device)\n",
    "    if model_name == \"DiffPool\":\n",
    "            out,gnn_loss, cluster_loss = model(data)  # Perform a single forward pass.\n",
    "            #y_true = data.y.reshape(-1,3)\n",
    "    elif model_name == \"TreeLSTM\":\n",
    "        n = data.x.shape[0]\n",
    "        h = torch.zeros((n, architecture_kwargs[\"n_hidden_channels\"]))\n",
    "        c = torch.zeros((n, architecture_kwargs[\"n_hidden_channels\"]))\n",
    "        out = model(\n",
    "            data,\n",
    "            h = h,\n",
    "            c = c,\n",
    "            embeddings = data.x\n",
    "            )\n",
    "    else:\n",
    "        out = model(data)\n",
    "\n",
    "    out_array = out.detach().cpu().numpy()\n",
    "    out_labels = data.y.numpy().reshape(-1)\n",
    "    #print(f\"out_array.shape = {out_array.shape}, out_labels.shape = {out_labels.shape}\")\n",
    "    \n",
    "#     if out_array.shape[0] != out_labels.shape[0]:\n",
    "#         raise Exception(\"\")\n",
    "    \n",
    "    embeddings.append(out_array)\n",
    "    labels.append(out_labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "embeddings = np.vstack(embeddings)\n",
    "labels = np.hstack(labels)\n",
    "\n",
    "embedding_df = pd.DataFrame(embeddings)\n",
    "embedding_df[\"cell_type\"] = labels\n",
    "\n",
    "import general_utils as gu\n",
    "decoder_map = dict([(v,k) if k is not None else (v,\"Unknown\") for k,v in cell_type_map.items()])\n",
    "\n",
    "import pandas_utils as pu\n",
    "embedding_df[\"cell_type\"] = pu.new_column_from_dict_mapping(embedding_df,decoder_map,column_name = \"cell_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(embedding_df[\"cell_type\"].to_numpy(),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_idx = embedding_df.query(\"cell_type != 'Unknown'\").index.to_numpy()\n",
    "labeled_mask_plotting = np.zeros(len(embedding_df))\n",
    "labeled_mask_plotting[labeled_idx] = 1\n",
    "labeled_mask_plotting = labeled_mask_plotting.astype(\"bool\")\n",
    "labeled_mask_plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Plotting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import visualizations_ml as vml\n",
    "n_components = 3\n",
    "import dimensionality_reduction_ml as dru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ml as pdml\n",
    "X_data,y_labels = pdml.X_y(embedding_df,\"cell_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_data[labeled_mask_plotting].to_numpy().astype(\"float\")\n",
    "y = y_labels[labeled_mask_plotting].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep) PCA Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_components_test=10\n",
    "pca_data = dru.pca_analysis(\n",
    "    X,\n",
    "    n_components=n_components_test,\n",
    "    plot_sqrt_eigvals=False,\n",
    "    plot_perc_variance_explained=True\n",
    ")\n",
    "\n",
    "X_pca = pca_data[\"data_proj\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/meshAfterParty/meshAfterParty/')\n",
    "import datajoint_utils as du\n",
    "import cell_type_utils as ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality_reduction_ml as dru\n",
    "import cell_type_utils as ctu\n",
    "dru.dimensionality_reduction_by_method(\n",
    "    method=\"pca\",\n",
    "    X=X[y!= \"Unknown\"],\n",
    "    y = y[y != \"Unknown\"],\n",
    "    n_components =3,\n",
    "    plot=True,\n",
    "    plot_kwargs=dict(\n",
    "    target_to_color = ctu.cell_type_fine_color_map,\n",
    "        ndim = 3,\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality_reduction_ml as dru\n",
    "dru.dimensionality_reduction_by_method(\n",
    "    method=\"umap\",\n",
    "    X=X[y!= \"Unknown\"],\n",
    "    y = y[y != \"Unknown\"],\n",
    "    n_components =3,\n",
    "    plot=True,\n",
    "    plot_kwargs=dict(\n",
    "    target_to_color = ctu.cell_type_fine_color_map,\n",
    "        ndim = 3,\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality_reduction_ml as dru\n",
    "dru.dimensionality_reduction_by_method(\n",
    "    method=\"umap\",\n",
    "    X=X[y!= \"Unknown\"],\n",
    "    y = y[y != \"Unknown\"],\n",
    "    n_components =2,\n",
    "    plot=True,\n",
    "    plot_kwargs=dict(\n",
    "    target_to_color = ctu.cell_type_fine_color_map,\n",
    "        ndim = 3,\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality_reduction_ml as dru\n",
    "dru.dimensionality_reduction_by_method(\n",
    "    method=\"isomap\",\n",
    "    X=X[y!= \"Unknown\"],\n",
    "    y = y[y != \"Unknown\"],\n",
    "    n_components =2,\n",
    "    plot=True,\n",
    "    plot_kwargs=dict(\n",
    "    target_to_color = ctu.cell_type_fine_color_map,\n",
    "        ndim = 3,\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality_reduction_ml as dru\n",
    "dru.dimensionality_reduction_by_method(\n",
    "    method=\"tsne\",\n",
    "    X=X[y!= \"Unknown\"],\n",
    "    y = y[y != \"Unknown\"],\n",
    "    n_components =3,\n",
    "    plot=True,\n",
    "    plot_kwargs=dict(\n",
    "    target_to_color = ctu.cell_type_fine_color_map,\n",
    "        ndim = 3,\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality_reduction_ml as dru\n",
    "dru.dimensionality_reduction_by_method(\n",
    "    method=\"tsne\",\n",
    "    X=X[y!= \"Unknown\"],\n",
    "    y = y[y != \"Unknown\"],\n",
    "    n_components =2,\n",
    "    plot=True,\n",
    "    plot_kwargs=dict(\n",
    "    target_to_color = ctu.cell_type_fine_color_map,\n",
    "        ndim = 3,\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimensionality_reduction_ml as dru\n",
    "dru.dimensionality_reduction_by_method(\n",
    "    method=\"tsne\",\n",
    "    X=X_pca[y!= \"Unknown\"],\n",
    "    y = y[y != \"Unknown\"],\n",
    "    n_components =2,\n",
    "    plot=True,\n",
    "    plot_kwargs=dict(\n",
    "    target_to_color = ctu.cell_type_fine_color_map,\n",
    "        ndim = 3,\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
