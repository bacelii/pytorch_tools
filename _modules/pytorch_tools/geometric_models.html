<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pytorch_tools.geometric_models &mdash; pytorch_tools  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            pytorch_tools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">pytorch_tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pytorch_tools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pytorch_tools.geometric_models</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pytorch_tools.geometric_models</h1><div class="highlight"><pre>
<span></span><span class="sd">&#39;&#39;&#39;</span>

<span class="sd">Notes: </span>
<span class="sd">Usually only have to use the batch variable when doing global pooling</span>






<span class="sd">Source: https://github.com/AntonioLonga/PytorchGeometricTutorial/blob/main/Tutorial16/Tutorial16.ipynb</span>

<span class="sd">Note: This requires the data to be a dense matrix </span>
<span class="sd">1. so need to T.ToDense() transform</span>
<span class="sd">2. and the DenseDataLoader</span>

<span class="sd">-- Still had bugs and couldn&#39;t get to work</span>





<span class="sd">Official source: https://github.com/RexYing/diffpool</span>

<span class="sd">pyg implementation paper source = https://github.com/VoVAllen/diffpool</span>



<span class="sd">Tutorial: https://docs.dgl.ai/en/0.6.x/tutorials/models/2_small_graph/3_tree-lstm.html </span>

<span class="sd">Code: https://github.com/dmlc/dgl/blob/master/examples/pytorch/tree_lstm/tree_lstm.py</span>

<span class="sd">Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks</span>
<span class="sd">https://arxiv.org/abs/1503.00075</span>



<span class="sd">from . import geometric_models as gm</span>
<span class="sd">sys.path.append(&quot;/pytorch_tools/pytorch_tools/HGP_SL&quot;)</span>
<span class="sd">import models</span>

<span class="sd">model_name = &quot;HGP_SL&quot;</span>
<span class="sd">n_epochs = 500</span>


<span class="sd">architecture_kwargs = dict(</span>
<span class="sd">    n_hidden_channels = 8, </span>
<span class="sd">    #first_heads=8, </span>
<span class="sd">    #output_heads=1, </span>
<span class="sd">    #dropout=0.6,</span>
<span class="sd">    #global_pool_type=&quot;mean&quot;</span>
<span class="sd">)</span>

<span class="sd">model = models.Model(</span>
<span class="sd">    dataset_num_node_features=dataset.num_node_features,</span>
<span class="sd">    dataset_num_classes=dataset.num_classes,</span>
<span class="sd">    **architecture_kwargs</span>
<span class="sd">    )</span>




<span class="sd">GraphSAGE did not import: </span>

<span class="sd">from torch_geometric.nn import SAGEConv</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Source: https://colab.research.google.com/github/sachinsharma9780/interactive_tutorials/blob/master/notebooks/example_output/Comprehensive_GraphSage_Guide_with_PyTorchGeometric_Output.ipynb#scrollTo=ROXBserO_amj</span>


<span class="sd">How GraphSAGE is different: </span>

<span class="sd">The GraphSage is different from GCNs is two ways: i.e.</span>
<span class="sd">1) Instead of taking the entire K-hop neighborhood of a </span>
<span class="sd">    target node, GraphSage first samples or prune the K-hop</span>
<span class="sd">    neighborhood computation graph and then perform the </span>
<span class="sd">    feature aggregation operation on this sampled graph </span>
<span class="sd">    in order to generate the embeddings for a target node. </span>
<span class="sd">2) During the learning process, in order to generate the node</span>
<span class="sd">    embeddings; GraphSage learns the aggregator function </span>
<span class="sd">    whereas GCNs make use of the symmetrically normalized </span>
<span class="sd">    graph Laplacian.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">class SAGE(torch.nn.Module):</span>
<span class="sd">    def __init__(</span>
<span class="sd">        self, </span>
<span class="sd">        dataset_num_node_features,</span>
<span class="sd">        n_hidden_channels, </span>
<span class="sd">        dataset_num_classes,</span>
<span class="sd">        n_layers=3):</span>
<span class="sd">        super(SAGE, self).__init__()</span>

<span class="sd">        self.num_layers = n_layers</span>

<span class="sd">        self.convs = torch.nn.ModuleList()</span>
<span class="sd">        self.convs.append(SAGEConv(dataset_num_node_features, n_hidden_channels))</span>
<span class="sd">        for _ in range(n_layers - 2):</span>
<span class="sd">            self.convs.append(SAGEConv(n_hidden_channels, n_hidden_channels))</span>
<span class="sd">        self.convs.append(SAGEConv(n_hidden_channels, dataset_num_classes))</span>

<span class="sd">    def reset_parameters(self):</span>
<span class="sd">        for conv in self.convs:</span>
<span class="sd">            conv.reset_parameters()</span>


<span class="sd">&#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">ceil</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">DenseGCNConv</span> <span class="k">as</span> <span class="n">DenseGCNConv</span><span class="p">,</span> <span class="n">dense_diff_pool</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GATConv</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">SAGEConv</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span><span class="p">,</span><span class="n">global_add_pool</span><span class="p">,</span><span class="n">global_mean_pool</span><span class="p">,</span><span class="n">global_sort_pool</span><span class="p">,</span><span class="n">global_max_pool</span>
<span class="kn">import</span> <span class="nn">dgl</span>
<span class="kn">import</span> <span class="nn">dgl.function</span> <span class="k">as</span> <span class="nn">fn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<div class="viewcode-block" id="Classifier"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.Classifier">[docs]</a><span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="Classifier.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.Classifier.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_classes</span><span class="p">,</span>
        <span class="n">n_inputs</span><span class="p">,</span>
        <span class="n">n_hidden</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;ReLU&quot;</span><span class="p">,</span>
        <span class="n">n_hidden_layers</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">f</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">softmax</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">):</span>
        
        <span class="k">if</span> <span class="n">n_hidden</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="n">activation_function</span>
        <span class="n">hid_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">n_hidden_layers</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">hid_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_hidden_layers</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">input_stage</span> <span class="o">=</span> <span class="n">n_inputs</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">input_stage</span><span class="o">=</span> <span class="n">n_hidden</span>
                <span class="n">hid_layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_stage</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)]</span>
                <span class="k">if</span> <span class="n">use_bn</span><span class="p">:</span>
                    <span class="n">hid_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">))</span>
                <span class="n">hid_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

            <span class="n">hid_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">hid_layers</span>
                                        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">softmax</span></div>

<div class="viewcode-block" id="Classifier.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.Classifier.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div></div>
    

<div class="viewcode-block" id="ClassifierBase"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ClassifierBase">[docs]</a><span class="k">class</span> <span class="nc">ClassifierBase</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="ClassifierBase.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ClassifierBase.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_classes</span><span class="p">,</span>
        <span class="n">n_inputs</span><span class="p">,</span>
        <span class="n">n_hidden</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
        <span class="n">n_hidden_layers</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">hidden_units_divisor</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">softmax</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassifierBase</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Our final linear layer will define our output</span>
        <span class="k">if</span> <span class="n">n_hidden_layers</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_classes</span>
        <span class="k">elif</span> <span class="n">n_hidden</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_inputs</span> <span class="o">//</span> <span class="n">hidden_units_divisor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin0</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span><span class="n">n_hidden</span><span class="p">)</span>
        <span class="n">previous_layers_units</span> <span class="o">=</span> <span class="n">n_hidden</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_layers</span> <span class="o">=</span> <span class="n">n_hidden_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_hidden_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">previous_layers_units</span><span class="p">))</span>
            
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">n_hidden_layers</span> <span class="o">-</span><span class="mi">1</span> <span class="p">:</span>
                <span class="n">new_layer_n_units</span> <span class="o">=</span> <span class="n">n_classes</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_layer_n_units</span> <span class="o">=</span> <span class="n">previous_layers_units</span> <span class="o">//</span> <span class="n">hidden_units_divisor</span>
                
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;lin</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">Linear</span><span class="p">(</span><span class="n">previous_layers_units</span><span class="p">,</span> <span class="n">new_layer_n_units</span><span class="p">))</span>
            <span class="n">previous_layers_units</span> <span class="o">=</span> <span class="n">new_layer_n_units</span>
            
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">activation_function</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="n">activation_function</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">softmax</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span></div>
            
<div class="viewcode-block" id="ClassifierBase.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ClassifierBase.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;lin</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div></div>
                
        
        
    
<div class="viewcode-block" id="ClassifierFlat"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ClassifierFlat">[docs]</a><span class="k">class</span> <span class="nc">ClassifierFlat</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="ClassifierFlat.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ClassifierFlat.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_classes</span><span class="p">,</span>
        <span class="n">n_inputs</span><span class="p">,</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">softmax</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassifierFlat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">softmax</span></div>
        
<div class="viewcode-block" id="ClassifierFlat.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ClassifierFlat.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div></div>
        
    


<span class="c1"># ---------------- basic graph neural network models -----------</span>
<span class="c1"># Define our GCN class as a pytorch Module</span>
<div class="viewcode-block" id="GCNFlat"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNFlat">[docs]</a><span class="k">class</span> <span class="nc">GCNFlat</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="GCNFlat.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNFlat.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">n_hidden_channels</span><span class="p">,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span>
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">global_pool_weight</span> <span class="o">=</span> <span class="s2">&quot;node_weight&quot;</span><span class="p">,</span>
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">improved</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">GCNFlat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># We inherit from pytorch geometric&#39;s GCN class, and we initialize three layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv0</span> <span class="o">=</span> <span class="n">GCNConv</span><span class="p">(</span><span class="n">dataset_num_node_features</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        
        <span class="c1">#for other gcn features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gcn_normalize</span> <span class="o">=</span> <span class="n">normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gcn_improved</span> <span class="o">=</span> <span class="n">improved</span>
        
        <span class="k">if</span> <span class="n">use_bn</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bn0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">track_running_stats</span><span class="o">=</span><span class="n">track_running_stats</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">GCNConv</span><span class="p">(</span>
                <span class="n">n_hidden_channels</span><span class="p">,</span> 
                <span class="n">n_hidden_channels</span><span class="p">,</span>
                <span class="n">normalize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_normalize</span><span class="p">,</span>
                <span class="n">improved</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_improved</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">use_bn</span><span class="p">:</span> 
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">track_running_stats</span><span class="o">=</span><span class="n">track_running_stats</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span> <span class="o">=</span> <span class="n">n_layers</span>
        
        <span class="c1"># Our final linear layer will define our output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">dataset_num_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span> <span class="o">=</span> <span class="n">global_pool_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">gtu</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span> <span class="o">=</span> <span class="n">global_pool_weight</span></div>
        
        
                
        
<div class="viewcode-block" id="GCNFlat.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNFlat.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="c1"># 1. Obtain node embeddings </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    
        <span class="c1"># 2. Readout layer</span>
        <span class="k">if</span> <span class="s2">&quot;weight&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span><span class="p">:</span>
            <span class="n">weight_values</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span><span class="n">weight_values</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]</span>
        <span class="k">return</span> <span class="n">x</span></div>
    
<div class="viewcode-block" id="GCNFlat.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNFlat.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># 3. Apply a final classifier</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>
    
<div class="viewcode-block" id="GCNHierarchical"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchical">[docs]</a><span class="k">class</span> <span class="nc">GCNHierarchical</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: To run a GCN model but with </span>
<span class="sd">    multiple steps of pooling</span>
<span class="sd">    </span>
<span class="sd">    Ex: Testing the basic model</span>
<span class="sd">    curr_model = GCNHierarchical(</span>
<span class="sd">        dataset_num_node_features=len(features_to_output_pool0),</span>
<span class="sd">        dataset_num_classes=len(cell_type_map),</span>
<span class="sd">        n_hidden_channels = 32,</span>
<span class="sd">        n_hidden_channels_pool0 = [23,10,8],</span>
<span class="sd">        n_hidden_channels_pool1 = [30,17,4],</span>

<span class="sd">        num_node_features_pool1 = 1,</span>
<span class="sd">        num_node_features_pool2 = 2,</span>
<span class="sd">    )</span>
<span class="sd">    </span>
<span class="sd">    for jj,data in enumerate(test_loader):</span>
<span class="sd">        out = curr_model(data)</span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="GCNHierarchical.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchical.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">dataset_num_node_features</span><span class="p">,</span>
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_pool</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">global_pool_weight</span> <span class="o">=</span> <span class="s2">&quot;node_weight&quot;</span><span class="p">,</span>
        
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        
        <span class="c1"># -- parameters if not layer specific ---</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">edge_weight</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">edge_weight_name</span> <span class="o">=</span> <span class="s2">&quot;edge_weight&quot;</span><span class="p">,</span>
        <span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        
        <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">aggregate_layer_outputs</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">aggregate_layer_outputs_func</span> <span class="o">=</span> <span class="s2">&quot;concatenate&quot;</span><span class="p">,</span>
        <span class="n">residual_connections</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="c1">#-- example of how to define the pooling variables --</span>
        <span class="c1">#n_hidden_channels_pool0</span>
        <span class="c1">#n_layers_pool0</span>
        <span class="c1">#num_node_features_pool1</span>
        <span class="c1">#num_node_features_pool2</span>
        <span class="n">append_max_pool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">residual_connections</span> <span class="o">=</span> <span class="n">residual_connections</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span> <span class="o">=</span> <span class="n">aggregate_layer_outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs_func</span> <span class="o">=</span> <span class="n">aggregate_layer_outputs_func</span>
        
        <span class="k">if</span> <span class="n">n_pool</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">GCNHierarchical</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">=</span> <span class="n">n_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        
        <span class="c1"># -- for the pooling --</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span> <span class="o">=</span> <span class="n">global_pool_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">gtu</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span> <span class="o">=</span> <span class="n">global_pool_weight</span>
        
        <span class="c1"># --- for the edge weights ---</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span> <span class="o">=</span> <span class="n">edge_weight</span>
        <span class="k">if</span> <span class="n">add_self_loops</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="n">add_self_loops</span>
            
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;self.add_self_loops= </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight_name</span> <span class="o">=</span> <span class="n">edge_weight_name</span>
        
        
        <span class="c1"># We inherit from pytorch geometric&#39;s GCN class, and we initialize three layers</span>
        <span class="n">n_input_layer</span> <span class="o">=</span> <span class="n">dataset_num_node_features</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool_iter</span> <span class="o">=</span> <span class="n">n_pool</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pool_iter</span> <span class="o">=</span> <span class="n">n_pool</span>
            
        <span class="n">n_hidden_channels_for_aggregator</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pool_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool_iter</span><span class="p">):</span>
            <span class="n">suffix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_hidden_channels_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                                               <span class="n">n_hidden_channels</span><span class="p">)</span>
            
            
            
            <span class="k">if</span> <span class="n">n_hidden_channels_pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                
            <span class="k">if</span> <span class="ow">not</span> <span class="n">nu</span><span class="o">.</span><span class="n">is_array_like</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">):</span>
                <span class="n">n_layers_pool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_layers_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                                               <span class="n">n_layers</span><span class="p">)</span>
                <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_hidden_channels_pool</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">n_layers_pool</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_layers_pool</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">)</span>
<span class="c1">#                 if len(n_hidden_channels_pool) != n_layers_pool - 1:</span>
<span class="c1">#                     raise Exception(&quot;Not enough hidden layers defined&quot;)</span>
                
            <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">n_input_layer</span><span class="p">,</span><span class="n">n_hidden_channels_pool</span><span class="p">])</span>
                
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pool </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> n_hidden_channels_pool = </span><span class="si">{</span><span class="n">n_hidden_channels_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">n_hidden_channels_for_aggregator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
                
                <span class="n">n_input</span> <span class="o">=</span> <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">n_output</span> <span class="o">=</span> <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">GCNConv</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span><span class="n">add_self_loops</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span><span class="p">))</span>
                
                <span class="k">if</span> <span class="n">use_bn</span><span class="p">:</span> 
                    <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span>
                                <span class="n">n_output</span><span class="p">,</span>
                                <span class="n">track_running_stats</span><span class="o">=</span><span class="n">track_running_stats</span>
                    <span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;n_conv</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">n_layers_pool</span><span class="p">)</span>
            

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">==</span> <span class="n">pool_idx</span><span class="p">:</span>
                <span class="n">n_extra_features</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_extra_features</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num_node_features_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="n">n_input_layer</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">n_extra_features</span>
                <span class="p">)</span>
            
        <span class="c1"># now have to do the linear layers</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span><span class="p">:</span>
            <span class="n">lin_n_layers</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_hidden_channels_for_aggregator</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lin_n_layers</span> <span class="o">=</span> <span class="n">n_input_layer</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">append_max_pool</span> <span class="o">=</span> <span class="n">append_max_pool</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_max_pool</span><span class="p">:</span>
            <span class="n">lin_n_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">lin_n_layers</span>
            
        
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">lin_n_layers</span><span class="p">,</span> <span class="n">dataset_num_classes</span><span class="p">)</span></div>
        
                
<div class="viewcode-block" id="GCNHierarchical.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchical.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">pool_return</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_pool_before_return</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Purpose: To encode the data to a certain pool range</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">debug_encode</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">pool_return</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pool_return</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span><span class="c1"># self.pool_iter</span>
        
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        <span class="n">all_layer_x</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pool_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool_iter</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Working on Pool </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">suffix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">n_conv</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;n_conv</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="c1"># running the actual convolution</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conv</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Working on Layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span><span class="p">:</span>
                    <span class="n">edge_weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_weight_name</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">edge_weight</span> <span class="o">=</span> <span class="kc">None</span>
                    
                <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;edge_weight iter </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">edge_weight</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
                    <span class="n">x_old</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span>
                                                     <span class="n">edge_weight</span><span class="o">=</span><span class="n">edge_weight</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using bn iter </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_conv</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span> <span class="c1"># and (pool_idx == self.n_pool - 1):</span>
                    <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using act_fun </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span><span class="p">:</span>
                    <span class="n">all_layer_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                    
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">x_old</span><span class="p">])</span>
                    
            
            <span class="k">if</span> <span class="n">pool_return</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span>
            
            <span class="c1"># calculating the weights</span>
<span class="c1">#             if &quot;weight&quot; in self.global_pool_type:</span>
<span class="c1">#                 weight_values = getattr(data,f&quot;{self.global_pool_weight}_pool{pool_idx}&quot;)</span>
<span class="c1">#             else:</span>
<span class="c1">#                 weight_values = None</span>
            
            <span class="n">weight_values</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span><span class="si">}</span><span class="s2">_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">weight_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">weight_values</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
                
            <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Right before pooling weight_values = </span><span class="si">{</span><span class="n">weight_values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
            <span class="c1">#print(f&#39;weight_values = {weight_values}&#39;)</span>
            
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">==</span> <span class="n">pool_idx</span> <span class="ow">and</span> <span class="n">pool_return</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs_func</span> <span class="o">==</span> <span class="s2">&quot;concatenate&quot;</span><span class="p">:</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">all_layer_x</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs_func</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">all_layer_x</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">all_layer_x</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                        
                <span class="n">return_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">batch</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weight_values</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_max_pool</span><span class="p">:</span>
                    <span class="n">return_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">return_x</span><span class="p">,</span><span class="n">global_max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">batch</span><span class="p">)])</span>
                <span class="c1">#print(f&quot;return_x.shape = {return_x.shape}&quot;)</span>
                <span class="k">return</span> <span class="n">return_x</span>
            
            <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Did not return after first return&quot;</span><span class="p">)</span>
            
            <span class="c1"># getting the pooling information</span>
            <span class="n">next_pool</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">pool_vec</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">next_pool</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">pool_vec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">pool_vec</span> <span class="o">=</span> <span class="n">batch</span>
                <span class="n">need_batch</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">need_batch</span> <span class="o">=</span> <span class="kc">True</span>
            
<span class="c1">#             if pool_vec is None:</span>
<span class="c1">#                 if debug_encode:</span>
<span class="c1">#                     print(f&quot;Using the batch as the pooling&quot;)</span>
<span class="c1">#                 pool_vec = batch</span>
            
            <span class="c1"># getting the new feature matrix</span>
            
            
            <span class="n">x_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_vec</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weight_values</span><span class="p">)</span>
            <span class="n">x_pool</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;x_</span><span class="si">{</span><span class="n">next_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([]))</span>
            <span class="c1">#print(f&quot;x_pool = {x_pool}&quot;)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x_pre</span><span class="p">,</span><span class="n">x_pool</span><span class="p">])</span>
            
            
            
            
            <span class="c1">#getting new edge index</span>
            <span class="n">edge_index</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;edge_index_</span><span class="si">{</span><span class="n">next_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">global_mean_pool</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">pool_vec</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">pool_return</span> <span class="o">==</span> <span class="n">pool_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">need_batch</span><span class="p">:</span>
                    
                    <span class="k">if</span> <span class="n">batch_pool_before_return</span><span class="p">:</span>
                        <span class="n">return_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">batch</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weight_values</span><span class="p">)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_max_pool</span><span class="p">:</span>
                            <span class="n">return_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">return_x</span><span class="p">,</span><span class="n">global_max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">batch</span><span class="p">)])</span>
                        <span class="k">return</span> <span class="n">return_x</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">batch</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">x</span></div>
            
            
            
<div class="viewcode-block" id="GCNHierarchical.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchical.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span><span class="n">classifier_layer</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,):</span>
        <span class="c1">#print(f&quot;classifier_layer = {classifier_layer}&quot;)</span>
        <span class="c1">#print(f&quot;kwargs = {kwargs}&quot;)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># 3. Apply a final classifier</span>
        <span class="k">if</span> <span class="n">classifier_layer</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">x</span><span class="p">,</span><span class="n">batch</span> <span class="o">=</span> <span class="n">x</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span><span class="n">batch</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span></div></div>



<div class="viewcode-block" id="GCNHierarchicalOld"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchicalOld">[docs]</a><span class="k">class</span> <span class="nc">GCNHierarchicalOld</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: To run a GCN model but with </span>
<span class="sd">    multiple steps of pooling</span>
<span class="sd">    </span>
<span class="sd">    Ex: Testing the basic model</span>
<span class="sd">    curr_model = GCNHierarchical(</span>
<span class="sd">        dataset_num_node_features=len(features_to_output_pool0),</span>
<span class="sd">        dataset_num_classes=len(cell_type_map),</span>
<span class="sd">        n_hidden_channels = 32,</span>
<span class="sd">        n_hidden_channels_pool0 = [23,10,8],</span>
<span class="sd">        n_hidden_channels_pool1 = [30,17,4],</span>

<span class="sd">        num_node_features_pool1 = 1,</span>
<span class="sd">        num_node_features_pool2 = 2,</span>
<span class="sd">    )</span>
<span class="sd">    </span>
<span class="sd">    for jj,data in enumerate(test_loader):</span>
<span class="sd">        out = curr_model(data)</span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="GCNHierarchicalOld.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchicalOld.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">dataset_num_node_features</span><span class="p">,</span>
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_pool</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">global_pool_weight</span> <span class="o">=</span> <span class="s2">&quot;node_weight&quot;</span><span class="p">,</span>
        
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        
        <span class="c1"># -- parameters if not layer specific ---</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">edge_weight</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">edge_weight_name</span> <span class="o">=</span> <span class="s2">&quot;edge_weight&quot;</span><span class="p">,</span>
        
        <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="c1">#-- example of how to define the pooling variables --</span>
        <span class="c1">#n_hidden_channels_pool0</span>
        <span class="c1">#n_layers_pool0</span>
        <span class="c1">#num_node_features_pool1</span>
        <span class="c1">#num_node_features_pool2</span>
        <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">GCNHierarchical</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">=</span> <span class="n">n_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        
        <span class="c1"># -- for the pooling --</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span> <span class="o">=</span> <span class="n">global_pool_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">gtu</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span> <span class="o">=</span> <span class="n">global_pool_weight</span>
        
        <span class="c1"># --- for the edge weights ---</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span> <span class="o">=</span> <span class="n">edge_weight</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">True</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight_name</span> <span class="o">=</span> <span class="n">edge_weight_name</span>
        
        <span class="c1"># We inherit from pytorch geometric&#39;s GCN class, and we initialize three layers</span>
        <span class="n">n_input_layer</span> <span class="o">=</span> <span class="n">dataset_num_node_features</span>
        
        <span class="k">for</span> <span class="n">pool_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_pool</span><span class="p">):</span>
            <span class="n">suffix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_hidden_channels_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                                               <span class="n">n_hidden_channels</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">n_hidden_channels_pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                
            <span class="k">if</span> <span class="ow">not</span> <span class="n">nu</span><span class="o">.</span><span class="n">is_array_like</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">):</span>
                <span class="n">n_layers_pool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_layers_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                                               <span class="n">n_layers</span><span class="p">)</span>
                <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_hidden_channels_pool</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">n_layers_pool</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_layers_pool</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">)</span>
<span class="c1">#                 if len(n_hidden_channels_pool) != n_layers_pool - 1:</span>
<span class="c1">#                     raise Exception(&quot;Not enough hidden layers defined&quot;)</span>
                
            <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">n_input_layer</span><span class="p">,</span><span class="n">n_hidden_channels_pool</span><span class="p">])</span>
                
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pool </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> n_hidden_channels_pool = </span><span class="si">{</span><span class="n">n_hidden_channels_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">n_input</span> <span class="o">=</span> <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">n_output</span> <span class="o">=</span> <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">GCNConv</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span><span class="n">add_self_loops</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span><span class="p">))</span>
                
                <span class="k">if</span> <span class="n">use_bn</span><span class="p">:</span> 
                    <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span>
                                <span class="n">n_output</span><span class="p">,</span>
                                <span class="n">track_running_stats</span><span class="o">=</span><span class="n">track_running_stats</span>
                    <span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;n_conv</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">n_layers_pool</span><span class="p">)</span>
            
            <span class="n">n_input_layer</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> 
                <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num_node_features_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
        
        <span class="c1"># now have to do the linear layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_input_layer</span><span class="p">,</span> <span class="n">dataset_num_classes</span><span class="p">)</span></div>
        
                
<div class="viewcode-block" id="GCNHierarchicalOld.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchicalOld.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">pool_return</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Purpose: To encode the data to a certain pool range</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">debug_encode</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">pool_return</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pool_return</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span>
        
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">pool_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Working on Pool </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">suffix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">n_conv</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;n_conv</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="c1"># running the actual convolution</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conv</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Working on Layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span><span class="p">:</span>
                    <span class="n">edge_weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_weight_name</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">edge_weight</span> <span class="o">=</span> <span class="kc">None</span>
                    
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span>
                                                     <span class="n">edge_weight</span><span class="o">=</span><span class="n">edge_weight</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_conv</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">pool_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">pool_return</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span>
            
            <span class="c1"># getting the pooling information</span>
            <span class="n">next_pool</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">pool_idx</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">pool_vec</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">next_pool</span><span class="p">,</span><span class="n">batch</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pool_vec</span> <span class="o">=</span> <span class="n">batch</span>
            
<span class="c1">#             if pool_vec is None:</span>
<span class="c1">#                 if debug_encode:</span>
<span class="c1">#                     print(f&quot;Using the batch as the pooling&quot;)</span>
<span class="c1">#                 pool_vec = batch</span>
            
            <span class="c1"># getting the new feature matrix</span>
            <span class="c1"># 2. Readout layer</span>
            <span class="k">if</span> <span class="s2">&quot;weight&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span><span class="p">:</span>
                <span class="n">weight_values</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span><span class="si">}</span><span class="s2">_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">x_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_vec</span><span class="p">,</span><span class="n">weight_values</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x_pre</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_vec</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]</span>
        
        
            <span class="c1">#x_pre = self.global_pool_func(x,pool_vec)</span>
            
            <span class="k">try</span><span class="p">:</span>
                <span class="n">x_pool</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;x_</span><span class="si">{</span><span class="n">next_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([]))</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x_pre</span><span class="p">,</span><span class="n">x_pool</span><span class="p">])</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
            
            <span class="k">if</span> <span class="n">pool_return</span> <span class="o">==</span> <span class="n">pool_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span>
            
            <span class="c1">#getting new edge index</span>
            <span class="n">edge_index</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;edge_index_</span><span class="si">{</span><span class="n">next_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">global_mean_pool</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">pool_vec</span><span class="p">)</span></div>
            
            
<div class="viewcode-block" id="GCNHierarchicalOld.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCNHierarchicalOld.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># 3. Apply a final classifier</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>
        
                
    
<span class="c1"># ------------ FOR GRAPH SAGE IMPLEMENTATION --------------</span>
<span class="c1"># Define our GCN class as a pytorch Module</span>
<div class="viewcode-block" id="SAGEConvNet"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.SAGEConvNet">[docs]</a><span class="k">class</span> <span class="nc">SAGEConvNet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="SAGEConvNet.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.SAGEConvNet.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">n_hidden_channels</span><span class="p">,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span>
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        
        <span class="c1">#for the classifier</span>
        <span class="n">classifier_type</span> <span class="o">=</span> <span class="s2">&quot;Base&quot;</span><span class="p">,</span>
        <span class="n">n_hidden_layers_classifier</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">n_hidden_classifier</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
        <span class="n">hidden_units_divisor</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">activation_function_classifier</span> <span class="o">=</span> <span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
        
                <span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">SAGEConvNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># We inherit from pytorch geometric&#39;s GCN class, and we initialize three layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv0</span> <span class="o">=</span> <span class="n">GCNConv</span><span class="p">(</span><span class="n">dataset_num_node_features</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">SAGEConv</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span> <span class="o">=</span> <span class="n">n_layers</span>
        
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">activation_function</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="n">activation_function</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        
        <span class="c1"># Our final linear layer will define our output</span>
        <span class="k">if</span> <span class="n">classifier_type</span> <span class="o">==</span> <span class="s2">&quot;Base&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">ClassifierBase</span><span class="p">(</span>
                <span class="n">n_classes</span><span class="o">=</span><span class="n">dataset_num_classes</span><span class="p">,</span>
                <span class="n">n_inputs</span><span class="o">=</span><span class="n">n_hidden_channels</span><span class="p">,</span>
                <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden_classifier</span><span class="p">,</span>
                <span class="n">activation_function</span> <span class="o">=</span> <span class="n">activation_function_classifier</span><span class="p">,</span>
                <span class="n">n_hidden_layers</span> <span class="o">=</span> <span class="n">n_hidden_layers_classifier</span><span class="p">,</span>
                <span class="n">hidden_units_divisor</span> <span class="o">=</span> <span class="n">hidden_units_divisor</span><span class="p">,</span>
                <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                <span class="n">softmax</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">classifier_type</span> <span class="o">==</span> <span class="s2">&quot;Flat&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">ClassifierFlat</span><span class="p">(</span>
                <span class="n">n_classes</span><span class="o">=</span><span class="n">dataset_num_classes</span><span class="p">,</span>
                <span class="n">n_inputs</span><span class="o">=</span><span class="n">n_hidden_channels</span><span class="p">,</span>
                <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                <span class="n">softmax</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span>
                <span class="n">n_classes</span><span class="o">=</span><span class="n">dataset_num_classes</span><span class="p">,</span>
                <span class="n">n_inputs</span><span class="o">=</span><span class="n">n_hidden_channels</span><span class="p">,</span>
                <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden_classifier</span><span class="p">,</span>
                <span class="n">activation_function</span> <span class="o">=</span> <span class="n">activation_function_classifier</span><span class="p">,</span>
                <span class="n">n_hidden_layers</span> <span class="o">=</span> <span class="n">n_hidden_layers_classifier</span><span class="p">,</span>
                <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">softmax</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span></div>
            
        
<span class="c1">#         self.lin0 = Linear(n_hidden_channels,n_starting_units_classifier)</span>
<span class="c1">#         previous_layers_units = n_starting_units_classifier</span>
        
<span class="c1">#         self.n_hidden_layers_classifier = n_hidden_layers_classifier</span>
        
<span class="c1">#         for i in range(1,n_hidden_layers_classifier):</span>
            
<span class="c1">#             setattr(self,f&quot;bn{i-1}&quot;,torch.nn.BatchNorm1d(previous_layers_units))</span>
            
<span class="c1">#             if i == n_hidden_layers_classifier -1 :</span>
<span class="c1">#                 new_layer_n_units = dataset_num_classes</span>
<span class="c1">#             else:</span>
<span class="c1">#                 new_layer_n_units = previous_layers_units // hidden_units_divisor</span>
<span class="c1">#             setattr(self,f&quot;lin{i}&quot;,Linear(previous_layers_units, new_layer_n_units))</span>
<span class="c1">#             previous_layers_units = new_layer_n_units</span>
            
        
            
<span class="c1">#         if type(activation_function_classifier) == str:</span>
<span class="c1">#             self.act_func_clf = getattr(F,activation_function_classifier)</span>
<span class="c1">#         else:</span>
<span class="c1">#             self.act_func_clf = activation_function_classifier</span>
            
        
                
        
<div class="viewcode-block" id="SAGEConvNet.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.SAGEConvNet.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="c1"># 1. Obtain node embeddings </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    
        <span class="c1"># 2. Readout layer</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]</span>
        <span class="k">return</span> <span class="n">x</span></div>
    
<div class="viewcode-block" id="SAGEConvNet.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.SAGEConvNet.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># 3. Apply a final classifier</span>
<span class="c1">#         for i in range(self.n_hidden_layers_classifier):</span>
<span class="c1">#             x = F.dropout(x, p=0.5, training=self.training)</span>
<span class="c1">#             x = getattr(self,f&quot;lin{i}&quot;)(x)</span>
<span class="c1">#             if i &lt; self.n_hidden_layers_classifier - 1:</span>
<span class="c1">#                 x = getattr(self,f&quot;bn{i}&quot;)(x)</span>
<span class="c1">#                 x = self.act_func_clf(x)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>



<div class="viewcode-block" id="GCN"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCN">[docs]</a><span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="GCN.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCN.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">n_hidden_channels</span><span class="p">,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span>
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="c1">#for classifier:</span>
        <span class="n">n_hidden_layers_classifier</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        
        
                <span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># We inherit from pytorch geometric&#39;s GCN class, and we initialize three layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv0</span> <span class="o">=</span> <span class="n">GCNConv</span><span class="p">(</span><span class="n">dataset_num_node_features</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">GCNConv</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span> <span class="o">=</span> <span class="n">n_layers</span>
        
        <span class="c1"># Our final linear layer will define our output</span>
        <span class="c1">#self.lin = Linear(n_hidden_channels, dataset_num_classes)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        
        
        
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="n">dataset_num_classes</span><span class="p">,</span>
            <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">n_hidden_channels</span><span class="p">,</span>
            <span class="n">n_hidden_layers</span> <span class="o">=</span> <span class="n">n_hidden_layers_classifier</span><span class="p">,</span>
            <span class="n">activation_function</span><span class="o">=</span><span class="n">activation_function</span><span class="p">,</span>
            <span class="n">use_bn</span><span class="o">=</span><span class="n">use_bn</span>
        <span class="p">)</span></div>
                
        
<div class="viewcode-block" id="GCN.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCN.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="c1"># 1. Obtain node embeddings </span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span><span class="c1">#.to(self.device)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
                    
        <span class="c1"># 2. Readout layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]</span>
        <span class="k">return</span> <span class="n">x</span></div>
    
<div class="viewcode-block" id="GCN.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GCN.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#         # 3. Apply a final classifier</span>
<span class="c1">#         x = F.dropout(x, p=0.5, training=self.training)</span>
<span class="c1">#         x = self.lin(x)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>
    
    
<span class="c1"># ---------- Graph Attention Network -------------</span>

<div class="viewcode-block" id="GAT"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT">[docs]</a><span class="k">class</span> <span class="nc">GAT</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Source: https://github.com/marblet/GNN_models_pytorch_geometric/blob/master/models/gat.py</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="GAT.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">dataset_num_node_features</span><span class="p">,</span> 
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;elu&quot;</span><span class="p">,</span>
        
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        
        <span class="c1">#parameters for the GAT</span>
        <span class="n">heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
        <span class="n">first_heads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_heads</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>

    
        <span class="c1">#--- parameters for size of classifier</span>
        <span class="n">classifier_type</span> <span class="o">=</span> <span class="s2">&quot;Flat&quot;</span><span class="p">,</span>
        <span class="n">classifier_n_hidden</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">GAT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span> 
        <span class="k">if</span> <span class="n">first_heads</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conv0_heads</span> <span class="o">=</span> <span class="n">first_heads</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">conv0_heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv0</span> <span class="o">=</span> <span class="n">GATConv</span><span class="p">(</span><span class="n">dataset_num_node_features</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span>
                           <span class="n">heads</span><span class="o">=</span><span class="n">conv0_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn0&quot;</span><span class="p">,</span>
                           <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span>
                                    <span class="n">n_hidden_channels</span><span class="o">*</span><span class="n">conv0_heads</span><span class="p">,</span>
                                    <span class="n">track_running_stats</span><span class="o">=</span><span class="n">track_running_stats</span>
                        <span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        
        <span class="n">prev_heads</span> <span class="o">=</span> <span class="n">conv0_heads</span>
        
        
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">output_heads</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">convN_heads</span> <span class="o">=</span> <span class="n">output_heads</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">convN_heads</span> <span class="o">=</span> <span class="n">heads</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">GATConv</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="o">*</span><span class="n">prev_heads</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span>
                           <span class="n">heads</span><span class="o">=</span><span class="n">convN_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
            <span class="n">prev_heads</span> <span class="o">=</span> <span class="n">convN_heads</span>
            <span class="k">if</span> <span class="n">use_bn</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                       <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span>
                                <span class="n">n_hidden_channels</span><span class="o">*</span><span class="n">convN_heads</span><span class="p">,</span>
                                <span class="n">track_running_stats</span><span class="o">=</span><span class="n">track_running_stats</span>
                    <span class="p">))</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="k">if</span> <span class="n">global_pool_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="kc">None</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span> <span class="o">=</span> <span class="n">n_layers</span>
        
        <span class="k">if</span> <span class="n">classifier_type</span> <span class="o">==</span> <span class="s2">&quot;Flat&quot;</span><span class="p">:</span>
            <span class="n">classifier_class</span> <span class="o">=</span> <span class="n">ClassifierFlat</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">classifier_class</span> <span class="o">=</span> <span class="n">Classifier</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">last_n_heads</span> <span class="o">=</span> <span class="n">prev_heads</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">classifier_class</span><span class="p">(</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="n">dataset_num_classes</span><span class="p">,</span>
            <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">n_hidden_channels</span><span class="o">*</span><span class="n">prev_heads</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="GAT.reset_parameters"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT.reset_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gc1</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gc2</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span></div>

<div class="viewcode-block" id="GAT.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>    
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>
<div class="viewcode-block" id="GAT.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="GAT_old"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT_old">[docs]</a><span class="k">class</span> <span class="nc">GAT_old</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Source: https://github.com/marblet/GNN_models_pytorch_geometric/blob/master/models/gat.py</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="GAT_old.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT_old.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">dataset_num_node_features</span><span class="p">,</span> 
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
        <span class="n">first_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
        <span class="n">output_heads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GAT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gc1</span> <span class="o">=</span> <span class="n">GATConv</span><span class="p">(</span><span class="n">dataset_num_node_features</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span>
                           <span class="n">heads</span><span class="o">=</span><span class="n">first_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gc2</span> <span class="o">=</span> <span class="n">GATConv</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="o">*</span><span class="n">first_heads</span><span class="p">,</span> <span class="n">dataset_num_classes</span><span class="p">,</span>
                           <span class="n">heads</span><span class="o">=</span><span class="n">output_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="k">if</span> <span class="n">global_pool_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="GAT_old.reset_parameters"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT_old.reset_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gc1</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gc2</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span></div>

<div class="viewcode-block" id="GAT_old.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT_old.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>    
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gc1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gc2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>
<div class="viewcode-block" id="GAT_old.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GAT_old.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>
    
    
<div class="viewcode-block" id="BatchedGraphSAGE"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedGraphSAGE">[docs]</a><span class="k">class</span> <span class="nc">BatchedGraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="BatchedGraphSAGE.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedGraphSAGE.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">infeat</span><span class="p">,</span> 
        <span class="n">outfeat</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span>
        <span class="n">use_bn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">mean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">add_self</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_self</span> <span class="o">=</span> <span class="n">add_self</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">infeat</span><span class="p">,</span> <span class="n">outfeat</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span></div>

<div class="viewcode-block" id="BatchedGraphSAGE.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedGraphSAGE.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="c1">#data</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">adj</span><span class="p">,</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">):</span>
        <span class="c1">#x,adj,mask = data.x, data.adj, data.mask</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_self</span><span class="p">:</span>
            <span class="n">adj</span> <span class="o">=</span> <span class="n">adj</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">adj</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span>
            <span class="n">adj</span> <span class="o">=</span> <span class="n">adj</span> <span class="o">/</span> <span class="n">adj</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">h_k_N</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">adj</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">h_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">(</span><span class="n">h_k_N</span><span class="p">)</span>
        <span class="n">h_k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">h_k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">h_k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">h_k</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">h_k</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">h_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">h_k</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">h_k</span> <span class="o">=</span> <span class="n">h_k</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">h_k</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h_k</span></div></div>
    
    
<div class="viewcode-block" id="GraphSAGE"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GraphSAGE">[docs]</a><span class="k">class</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">dense_adj</span> <span class="o">=</span> <span class="kc">True</span>
    
<div class="viewcode-block" id="GraphSAGE.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GraphSAGE.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span> 
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
        <span class="c1">#dropout=0.6,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        
        
        <span class="c1">#parameters for the individual GraphSAGEs</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">use_bn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">mean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
        <span class="n">add_self</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        
        <span class="c1">#--- parameters for size of classifier</span>
        <span class="n">classifier_n_hidden</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">GraphSAGE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">conv0</span> <span class="o">=</span> <span class="n">BatchedGraphSAGE</span><span class="p">(</span>
            <span class="n">dataset_num_node_features</span><span class="p">,</span>
            <span class="n">n_hidden_channels</span><span class="p">,</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span>
            <span class="n">use_bn</span><span class="o">=</span><span class="n">use_bn</span><span class="p">,</span> 
            <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> 
            <span class="n">add_self</span><span class="o">=</span><span class="n">add_self</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">BatchedGraphSAGE</span><span class="p">(</span>
            <span class="n">n_hidden_channels</span><span class="p">,</span>
            <span class="n">n_hidden_channels</span><span class="p">,</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span>
            <span class="n">use_bn</span><span class="o">=</span><span class="n">use_bn</span><span class="p">,</span> 
            <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> 
            <span class="n">add_self</span><span class="o">=</span><span class="n">add_self</span><span class="p">))</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span> <span class="o">=</span> <span class="n">n_layers</span>
        
        <span class="c1">#self.act_func = getattr(F,activation_function)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span> <span class="o">=</span> <span class="n">global_pool_type</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="n">dataset_num_classes</span><span class="p">,</span>
            <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">n_hidden_channels</span><span class="p">,</span>
            <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">classifier_n_hidden</span><span class="p">,</span>
        <span class="p">)</span></div>
        
<div class="viewcode-block" id="GraphSAGE.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GraphSAGE.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span><span class="n">adj</span><span class="p">,</span><span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">adj</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">mask</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_conv</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
            
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1">#readout_x = self.global_pool_func(x, batch)  # [batch_size, hidden_channels]</span>
        <span class="n">readout_x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span><span class="p">)(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">readout_x</span></div>
    
<div class="viewcode-block" id="GraphSAGE.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.GraphSAGE.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">graph_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">graph_feat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div></div>
    
        
    

    
<span class="c1"># --------------------- ALL OF THE DIFFPOOL MODELS -------------</span>

    
<span class="c1"># ---- simple diff pool -------------</span>


<div class="viewcode-block" id="DiffPoolSimpleGNN"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSimpleGNN">[docs]</a><span class="k">class</span> <span class="nc">DiffPoolSimpleGNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
<div class="viewcode-block" id="DiffPoolSimpleGNN.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSimpleGNN.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">lin</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DiffPoolSimpleGNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DenseGCNConv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">normalize</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DenseGCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">normalize</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DenseGCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">normalize</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span></div>


<div class="viewcode-block" id="DiffPoolSimpleGNN.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSimpleGNN.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">adj</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span><span class="n">adj</span><span class="p">,</span><span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">adj</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">mask</span>
            
        
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">)):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[</span><span class="n">step</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="c1">#.to(self.device)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="p">[</span><span class="n">step</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span></div></div>
<div class="viewcode-block" id="DiffPoolGCN"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolGCN">[docs]</a><span class="k">class</span> <span class="nc">DiffPoolGCN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">dense_adj</span> <span class="o">=</span> <span class="kc">True</span>
<div class="viewcode-block" id="DiffPoolGCN.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolGCN.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span> 
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
        <span class="n">max_nodes</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
        <span class="n">pool_ratio</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span>
        <span class="n">n_pool_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        
        <span class="c1">#classifier arguments</span>
        <span class="n">classifier_flat</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">classifier_n_hidden</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        
        <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DiffPoolGCN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span> <span class="o">=</span> <span class="n">global_pool_type</span>
<span class="c1">#         if max_nodes &gt; dataset_num_node_features:</span>
<span class="c1">#             max_nodes = dataset_num_node_features</span>
        
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">pool_ratio</span> <span class="o">*</span> <span class="n">max_nodes</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes_by_layer</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset_num_node_features</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pool_layers</span> <span class="o">=</span> <span class="n">n_pool_layers</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_pool_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes_by_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">input_size</span> <span class="o">=</span> <span class="n">dataset_num_node_features</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_size</span> <span class="o">=</span> <span class="n">n_hidden_channels</span>
                
            <span class="c1">#self.gnn1_pool = DiffPoolSimpleGNN(dataset_num_node_features, n_hidden_channels, num_nodes)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;gnn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">,</span><span class="n">DiffPoolSimpleGNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">))</span>
            <span class="c1">#self.gnn1_embed = DiffPoolSimpleGNN(dataset_num_node_features, n_hidden_channels, n_hidden_channels)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;gnn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">_embed&quot;</span><span class="p">,</span><span class="n">DiffPoolSimpleGNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">))</span>

            <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">pool_ratio</span> <span class="o">*</span> <span class="n">num_nodes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">1</span>
    
                    
        <span class="c1">#self.gnn3_embed = DiffPoolSimpleGNN(n_hidden_channels, n_hidden_channels, n_hidden_channels, lin=False)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;gnn</span><span class="si">{</span><span class="n">n_pool_layers</span><span class="si">}</span><span class="s2">_embed&quot;</span><span class="p">,</span><span class="n">DiffPoolSimpleGNN</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">lin</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        
        
        <span class="k">if</span> <span class="n">classifier_flat</span><span class="p">:</span>
            <span class="n">classifier_class</span> <span class="o">=</span> <span class="n">ClassifierFlat</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">classifier_class</span> <span class="o">=</span> <span class="n">Classifier</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">classifier_class</span><span class="p">(</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="n">dataset_num_classes</span><span class="p">,</span>
            <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">n_hidden_channels</span><span class="p">,</span>
            <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">classifier_n_hidden</span><span class="p">,</span>
        <span class="p">)</span></div>

<span class="c1">#         self.lin1 = torch.nn.Linear(n_hidden_channels, n_hidden_channels)</span>
<span class="c1">#         self.lin2 = torch.nn.Linear(n_hidden_channels, dataset_num_classes)</span>

        
<div class="viewcode-block" id="DiffPoolGCN.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolGCN.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">return_loss</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span><span class="n">adj</span><span class="p">,</span><span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">adj</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">mask</span>
        
        <span class="n">gnn_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">cluster_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_pool_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
                
            <span class="c1">#s = self.gnn1_pool(x, adj, mask)</span>
            <span class="n">s</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;gnn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
            <span class="c1">#x = self.gnn1_embed(x, adj, mask)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;gnn</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">_embed&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

            <span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">l1</span><span class="p">,</span> <span class="n">e1</span> <span class="o">=</span> <span class="n">dense_diff_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
            <span class="n">gnn_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span>
            <span class="n">cluster_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e1</span><span class="p">)</span>
        <span class="c1">#x_1 = s_0.t() @ z_0</span>
        <span class="c1">#adj_1 = s_0.t() @ adj_0 @ s_0</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;gnn</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_pool_layers</span><span class="si">}</span><span class="s2">_embed&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span><span class="p">)(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_loss</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gnn_loss</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cluster_loss</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span></div>
<div class="viewcode-block" id="DiffPoolGCN.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolGCN.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span><span class="n">gnn_loss</span><span class="p">,</span><span class="n">cluster_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">return_loss</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">gnn_loss</span><span class="p">,</span> <span class="n">cluster_loss</span></div></div>
    
    
<span class="c1"># ----------- Graph Sage and Diff Pool ----------</span>


<div class="viewcode-block" id="BatchedDiffPool"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedDiffPool">[docs]</a><span class="k">class</span> <span class="nc">BatchedDiffPool</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="BatchedDiffPool.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedDiffPool.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">nfeat</span><span class="p">,</span> 
        <span class="n">nnext</span><span class="p">,</span> 
        <span class="n">nhid</span><span class="p">,</span> 
        <span class="n">is_final</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> 
        <span class="n">link_pred</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchedDiffPool</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">link_pred</span> <span class="o">=</span> <span class="n">link_pred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_final</span> <span class="o">=</span> <span class="n">is_final</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">BatchedGraphSAGE</span><span class="p">(</span><span class="n">nfeat</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">use_bn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assign_mat</span> <span class="o">=</span> <span class="n">BatchedGraphSAGE</span><span class="p">(</span><span class="n">nfeat</span><span class="p">,</span> <span class="n">nnext</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">use_bn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">link_pred_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_loss</span> <span class="o">=</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="BatchedDiffPool.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedDiffPool.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">adj</span><span class="p">,</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,):</span>
        <span class="c1">#x,adj,mask = data.x, data.adj, data.mask</span>
        <span class="n">z_l</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z_l</span></div>
<div class="viewcode-block" id="BatchedDiffPool.cluster"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedDiffPool.cluster">[docs]</a>    <span class="k">def</span> <span class="nf">cluster</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">adj</span><span class="p">,</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,):</span>
        <span class="c1">#x,adj,mask = data.x, data.adj, data.mask</span>
        <span class="n">s_l</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">assign_mat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">s_l</span></div>
        
<div class="viewcode-block" id="BatchedDiffPool.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.BatchedDiffPool.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="c1">#data,</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">adj</span><span class="p">,</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        
        <span class="n">z_l</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">adj</span><span class="p">,</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">s_l</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">adj</span><span class="p">,</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;s&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_l</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">xnext</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">s_l</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">z_l</span><span class="p">)</span>
        <span class="n">anext</span> <span class="o">=</span> <span class="p">(</span><span class="n">s_l</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">adj</span><span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">s_l</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">link_pred</span><span class="p">:</span>
            <span class="c1"># TODO: Masking padded s_l</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">link_pred_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">adj</span> <span class="o">-</span> <span class="n">s_l</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">s_l</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)))</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">entropy_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">s_l</span><span class="p">)</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">entropy_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_loss</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">entropy_loss</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">entropy_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">xnext</span><span class="p">,</span> <span class="n">anext</span></div></div>
    
    
<div class="viewcode-block" id="DiffPoolSAGE"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSAGE">[docs]</a><span class="k">class</span> <span class="nc">DiffPoolSAGE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="DiffPoolSAGE.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSAGE.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span> 
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
        <span class="n">max_nodes</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
        <span class="n">pool_ratio</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span>
        <span class="n">n_pool_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">link_pred</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        
        <span class="c1">#classifier parameters</span>
        <span class="n">classifier_n_hidden</span> <span class="o">=</span> <span class="mi">50</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">dataset_num_node_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">link_pred</span> <span class="o">=</span> <span class="n">link_pred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        
        
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">pool_ratio</span> <span class="o">*</span> <span class="n">max_nodes</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">1</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes_by_layer</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset_num_node_features</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pool_layers</span> <span class="o">=</span> <span class="n">n_pool_layers</span>
        
        <span class="n">layers_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_pool_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes_by_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">input_size</span> <span class="o">=</span> <span class="n">dataset_num_node_features</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_size</span> <span class="o">=</span> <span class="n">n_hidden_channels</span>
            <span class="n">layers_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BatchedGraphSAGE</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="n">layers_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BatchedGraphSAGE</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="n">layers_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BatchedDiffPool</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">n_hidden_channels</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">link_pred</span><span class="o">=</span><span class="n">link_pred</span><span class="p">))</span>
            
            <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">pool_ratio</span> <span class="o">*</span> <span class="n">num_nodes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">1</span>
            
        <span class="n">layers_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BatchedGraphSAGE</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="n">layers_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BatchedGraphSAGE</span><span class="p">(</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">n_hidden_channels</span><span class="p">,</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers_list</span><span class="p">)</span>
<span class="c1">#         self.layers = nn.ModuleList([</span>
<span class="c1">#             BatchedGraphSAGE(dataset_num_node_features, 30, device=self.device),</span>
<span class="c1">#             BatchedGraphSAGE(30, 30, device=self.device),</span>
<span class="c1">#             BatchedDiffPool(30, pool_size, 30, device=self.device, link_pred=link_pred),</span>
<span class="c1">#             BatchedGraphSAGE(30, 30, device=self.device),</span>
<span class="c1">#             BatchedGraphSAGE(30, 30, device=self.device),</span>
<span class="c1">#             # BatchedDiffPool(30, 1, 30, is_final=True, device=self.device)</span>
<span class="c1">#         ])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="n">dataset_num_classes</span><span class="p">,</span>
            <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">n_hidden_channels</span><span class="p">,</span>
            <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">classifier_n_hidden</span><span class="p">,</span>
        <span class="p">)</span>
    
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span> <span class="o">=</span> <span class="n">global_pool_type</span></div>
        <span class="c1"># writer.add_text(str(vars(self)))</span>

<div class="viewcode-block" id="DiffPoolSAGE.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSAGE.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span><span class="n">adj</span><span class="p">,</span><span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">adj</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">mask</span>
        
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">BatchedGraphSAGE</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">BatchedDiffPool</span><span class="p">):</span>
                <span class="c1"># TODO: Fix if condition</span>
                <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="n">x</span><span class="p">,</span> <span class="n">adj</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x</span><span class="p">,</span> <span class="n">adj</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="c1">#readout_x = self.global_pool_func(x, batch)  # [batch_size, hidden_channels]</span>
        <span class="n">readout_x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">global_pool_type</span><span class="p">)(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">readout_x</span></div>
<div class="viewcode-block" id="DiffPoolSAGE.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSAGE.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">graph_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">graph_feat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>
        

<div class="viewcode-block" id="DiffPoolSAGE.loss"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.DiffPoolSAGE.loss">[docs]</a>    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">link_pred</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">BatchedDiffPool</span><span class="p">):</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">link_pred_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">entropy_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">loss</span></div></div>
    
<span class="c1"># --------------------- TREE LSTM MODEL ------------------------</span>
    


<div class="viewcode-block" id="ChildSumTreeLSTMCell"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ChildSumTreeLSTMCell">[docs]</a><span class="k">class</span> <span class="nc">ChildSumTreeLSTMCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="ChildSumTreeLSTMCell.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ChildSumTreeLSTMCell.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_size</span><span class="p">,</span> <span class="n">h_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ChildSumTreeLSTMCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_iou</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">x_size</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U_iou</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h_size</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_iou</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h_size</span><span class="p">,</span> <span class="n">h_size</span><span class="p">)</span></div>

<div class="viewcode-block" id="ChildSumTreeLSTMCell.message_func"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ChildSumTreeLSTMCell.message_func">[docs]</a>    <span class="k">def</span> <span class="nf">message_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;h&#39;</span><span class="p">:</span> <span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]}</span></div>

<div class="viewcode-block" id="ChildSumTreeLSTMCell.reduce_func"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ChildSumTreeLSTMCell.reduce_func">[docs]</a>    <span class="k">def</span> <span class="nf">reduce_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
        <span class="n">h_tild</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">U_f</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]))</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">f</span> <span class="o">*</span> <span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;iou&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">U_iou</span><span class="p">(</span><span class="n">h_tild</span><span class="p">),</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="n">c</span><span class="p">}</span></div>

<div class="viewcode-block" id="ChildSumTreeLSTMCell.apply_node_func"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.ChildSumTreeLSTMCell.apply_node_func">[docs]</a>    <span class="k">def</span> <span class="nf">apply_node_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
        <span class="n">iou</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;iou&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_iou</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">iou</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">th</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o</span><span class="p">),</span> <span class="n">th</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">u</span> <span class="o">+</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">o</span> <span class="o">*</span> <span class="n">th</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;h&#39;</span><span class="p">:</span> <span class="n">h</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="n">c</span><span class="p">}</span></div></div>

<div class="viewcode-block" id="TreeLSTMCell"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTMCell">[docs]</a><span class="k">class</span> <span class="nc">TreeLSTMCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="TreeLSTMCell.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTMCell.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_size</span><span class="p">,</span> <span class="n">h_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TreeLSTMCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_iou</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">x_size</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U_iou</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_iou</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">h_size</span><span class="p">)</span></div>

<div class="viewcode-block" id="TreeLSTMCell.message_func"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTMCell.message_func">[docs]</a>    <span class="k">def</span> <span class="nf">message_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;h&#39;</span><span class="p">:</span> <span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]}</span></div>

<div class="viewcode-block" id="TreeLSTMCell.reduce_func"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTMCell.reduce_func">[docs]</a>    <span class="k">def</span> <span class="nf">reduce_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
        <span class="n">h_cat</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">U_f</span><span class="p">(</span><span class="n">h_cat</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">f</span> <span class="o">*</span> <span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;iou&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">U_iou</span><span class="p">(</span><span class="n">h_cat</span><span class="p">),</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="n">c</span><span class="p">}</span></div>

<div class="viewcode-block" id="TreeLSTMCell.apply_node_func"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTMCell.apply_node_func">[docs]</a>    <span class="k">def</span> <span class="nf">apply_node_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
        <span class="n">iou</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;iou&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_iou</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">iou</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">th</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o</span><span class="p">),</span> <span class="n">th</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">u</span> <span class="o">+</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">o</span> <span class="o">*</span> <span class="n">th</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;h&#39;</span> <span class="p">:</span> <span class="n">h</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span> <span class="p">:</span> <span class="n">c</span><span class="p">}</span></div></div>


<div class="viewcode-block" id="TreeLSTM"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTM">[docs]</a><span class="k">class</span> <span class="nc">TreeLSTM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">directed</span> <span class="o">=</span> <span class="kc">True</span>
<div class="viewcode-block" id="TreeLSTM.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTM.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="c1">#num_vocabs,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span>
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        <span class="c1">#h_size,</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">cell_type</span> <span class="o">=</span> <span class="s2">&quot;nary&quot;</span><span class="p">,</span>
        <span class="n">global_pool_type</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span>
        <span class="p">):</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">TreeLSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">#self.x_size = x_size</span>
        <span class="c1">#self.embedding = nn.Embedding(num_vocabs, x_size)</span>
<span class="c1">#         if pretrained_emb is not None:</span>
<span class="c1">#             print(&#39;Using glove&#39;)</span>
<span class="c1">#             self.embedding.weight.data.copy_(pretrained_emb)</span>
<span class="c1">#             self.embedding.weight.requires_grad = True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">n_hidden_channels</span><span class="p">,</span> 
            <span class="n">dataset_num_classes</span><span class="p">)</span>
        
        <span class="n">cell</span> <span class="o">=</span> <span class="n">TreeLSTMCell</span> <span class="k">if</span> <span class="n">cell_type</span> <span class="o">==</span> <span class="s1">&#39;nary&#39;</span> <span class="k">else</span> <span class="n">ChildSumTreeLSTMCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">cell</span><span class="p">(</span>
            <span class="n">dataset_num_node_features</span><span class="p">,</span>
            <span class="n">n_hidden_channels</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">global_pool_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="kc">None</span></div>
            

<div class="viewcode-block" id="TreeLSTM.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTM.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">,</span>
        <span class="n">h</span><span class="p">,</span>
        <span class="n">c</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">):</span>
<span class="w">        </span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute tree-lstm prediction given a batch.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch : dgl.data.SSTBatch</span>
<span class="sd">            The data batch.</span>
<span class="sd">        h : Tensor</span>
<span class="sd">            Initial hidden state.</span>
<span class="sd">        c : Tensor</span>
<span class="sd">            Initial cell state.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        logits : Tensor</span>
<span class="sd">            The prediction of each node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># to heterogenous graph</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">dglu</span><span class="o">.</span><span class="n">g_from_data</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        
        <span class="c1">#print(f&quot;g = {g}&quot;)</span>
        
<span class="c1">#         print(f&quot;g.edges = {g.edges()}&quot;)</span>
<span class="c1">#         print(f&quot;list(dgl.topological_nodes_generator(g)) = {list(dgl.topological_nodes_generator(g))}&quot;)</span>
        <span class="c1"># feed embedding</span>
        <span class="c1">#embeds = self.embedding(batch.wordid * batch.mask)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="c1"># * batch.mask</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">&#39;iou&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">W_iou</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">embeddings</span><span class="p">),</span>
            <span class="c1">#embeddings</span>
        <span class="p">)</span><span class="c1">#* batch.mask.float().unsqueeze(-1)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
        <span class="c1"># propagate</span>
        <span class="n">dgl</span><span class="o">.</span><span class="n">prop_nodes_topo</span><span class="p">(</span><span class="n">g</span><span class="p">,</span>
                            <span class="n">message_func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">message_func</span><span class="p">,</span>
                            <span class="n">reduce_func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">reduce_func</span><span class="p">,</span>
                            <span class="n">apply_node_func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">apply_node_func</span><span class="p">)</span>
        <span class="c1"># compute logits</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;h&#39;</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span></div>
        
<div class="viewcode-block" id="TreeLSTM.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.geometric_models.TreeLSTM.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">,</span>
        <span class="n">h</span><span class="p">,</span>
        <span class="n">c</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">):</span>
        
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
        <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
        <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">,</span>
        <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
        
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div></div>
    
<span class="c1"># ------------- Models that did not work ------------</span>

<span class="c1">#--- from pytorch_tools ---</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">dgl_utils</span> <span class="k">as</span> <span class="n">dglu</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">geometric_tensor_utils</span> <span class="k">as</span> <span class="n">gtu</span>

<span class="c1">#--- from python_tools ---</span>
<span class="kn">from</span> <span class="nn">python_tools</span> <span class="kn">import</span> <span class="n">numpy_utils</span> <span class="k">as</span> <span class="n">nu</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Brendan Celii.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>