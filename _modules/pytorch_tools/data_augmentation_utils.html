<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pytorch_tools.data_augmentation_utils &mdash; pytorch_tools  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            pytorch_tools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">pytorch_tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pytorch_tools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pytorch_tools.data_augmentation_utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pytorch_tools.data_augmentation_utils</h1><div class="highlight"><pre>
<span></span><span class="sd">&#39;&#39;&#39;</span>

<span class="sd">Deepmind paper that talks about training with high confidence samples: </span>

<span class="sd">https://www.nature.com/articles/s41586-021-03819-2.pdf</span>
<span class="sd">- noisy student self-distillation</span>

<span class="sd">https://github.com/rish-16/grafog</span>
<span class="sd">- general procedure</span>
<span class="sd">1) Write a class that inherits from module and overloads the forward function</span>

<span class="sd">2) create composition of node and edge augmentations</span>
<span class="sd">3) At every epoch fun the data through the augmentation</span>

<span class="sd">Ex: </span>

<span class="sd">node_aug = T.Compose([</span>
<span class="sd">    T.NodeDrop(p=0.45),</span>
<span class="sd">    T.NodeMixUp(lamb=0.5, classes=7),</span>
<span class="sd">    ...</span>
<span class="sd">])</span>

<span class="sd">edge_aug = T.Compose([</span>
<span class="sd">    T.EdgeDrop(0=0.15),</span>
<span class="sd">    T.EdgeFeatureMasking()</span>
<span class="sd">])</span>

<span class="sd">data = CoraFull()</span>
<span class="sd">model = ...</span>

<span class="sd">for epoch in range(10): # begin training loop</span>
<span class="sd">    new_data = node_aug(data) # apply the node augmentation(s)</span>
<span class="sd">    new_data = edge_aug(new_data) # apply the edge augmentation(s)</span>
<span class="sd">    </span>
<span class="sd">    x, y = new_data.x, new_data.y</span>
<span class="sd">    ...</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch_geometric</span> <span class="k">as</span> <span class="nn">tg</span>


<span class="c1"># ----------- utility functions for augmentation classes ----- </span>
<span class="n">pool_attributes_affected_by_nodes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;node_weight_pool0&quot;</span><span class="p">,</span>
    <span class="s2">&quot;pool1&quot;</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="set_ptr"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.set_ptr">[docs]</a><span class="k">def</span> <span class="nf">set_ptr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">return_ptr</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: to compute the new ptr</span>
<span class="sd">    if a batch is readjusted</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ptr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">))])</span>
    <span class="k">if</span> <span class="n">return_ptr</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ptr</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span><span class="o">.</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">ptr</span></div>
        
        
<div class="viewcode-block" id="mask_addition_if_totally_eliminated"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.mask_addition_if_totally_eliminated">[docs]</a><span class="k">def</span> <span class="nf">mask_addition_if_totally_eliminated</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">mask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: To come up with a mask indicating</span>
<span class="sd">    what positions need to be fixed in order for the</span>
<span class="sd">    mask not to totally eliminated a batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span>
    
    <span class="n">batch_after_elim</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span>
    <span class="n">remaining_batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">batch_after_elim</span><span class="p">)</span>
    <span class="n">batch_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_idx</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    <span class="n">batch_mask</span><span class="p">[</span><span class="n">remaining_batches</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">mask_fix</span> <span class="o">=</span> <span class="n">tenu</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">batch_idx</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">],</span><span class="n">return_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mask_fix</span></div>

<div class="viewcode-block" id="drop_nodes"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.drop_nodes">[docs]</a><span class="k">def</span> <span class="nf">drop_nodes</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">clone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">node_attributes_to_adjust</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">debug_time</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: to delete certain nodes from a dataset</span>
<span class="sd">    based on a mask</span>
<span class="sd">    </span>
<span class="sd">    Pseudocode: </span>
<span class="sd">    1) Generate the mask if not defined</span>
<span class="sd">    2) Get the node_idx of the mask</span>
<span class="sd">    3) Generate vector of the new node ids</span>
<span class="sd">    </span>
<span class="sd">    4) Find the new edges by dropping the edges with the nodes</span>
<span class="sd">    and then finding the new edge</span>
<span class="sd">    </span>
<span class="sd">    Ex: </span>
<span class="sd">    from torch_geometric.data import Data</span>
<span class="sd">    import numpy as np</span>
<span class="sd">    from pytorch_tools import geometric_dataset_utils as gdu</span>

<span class="sd">    d = dau.example_data_obj()</span>
<span class="sd">    new_d = dau.drop_nodes(</span>
<span class="sd">        d,</span>
<span class="sd">        p=0.5,</span>
<span class="sd">        verbose = True,</span>
<span class="sd">        #node_attributes_to_adjust=pool_attributes_affected_by_nodes</span>
<span class="sd">    )</span>
<span class="sd">    </span>
<span class="sd">    Ex: With a prescribed mask</span>
<span class="sd">    </span>
<span class="sd">    d = dau.example_data_obj()</span>
<span class="sd">    new_d = dau.drop_nodes(</span>
<span class="sd">        d,</span>
<span class="sd">        mask = torch.tensor([0,0,1,0,0,0],dtype=torch.bool),</span>
<span class="sd">        p=0.5,</span>
<span class="sd">        verbose = True,</span>
<span class="sd">        #node_attributes_to_adjust=pool_attributes_affected_by_nodes</span>
<span class="sd">    )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span>
    
    <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">debug_batch</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">debug_time</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">clone</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        
    <span class="c1">#data.batch.shape</span>
    <span class="k">if</span> <span class="n">debug_batch</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Beginning&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.x.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.batch.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.ptr = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ptr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
    
    <span class="k">if</span> <span class="n">node_attributes_to_adjust</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">node_attributes_to_adjust</span> <span class="o">=</span> <span class="n">pool_attributes_affected_by_nodes</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        
    
        
    <span class="n">node_attributes_to_adjust</span> <span class="o">=</span> <span class="n">nu</span><span class="o">.</span><span class="n">convert_to_array_like</span><span class="p">(</span><span class="n">node_attributes_to_adjust</span><span class="p">)</span>
    <span class="n">node_attributes_to_adjust</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span>
        
    <span class="n">n_nodes</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tenu</span><span class="o">.</span><span class="n">random_mask</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;filter_away_mask = </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># -- want to check that no neuron is completely filtered away</span>
    <span class="c1"># -- and if so then adds back the nodes ----</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Psuedocode: </span>
<span class="sd">    1) Use the mask to index to the batch to get the leftover batches</span>
<span class="sd">    2) Get the batches that are totally eliminated</span>
<span class="sd">    3) Then find the positions in the map where the eliminated masks are and turn back to true</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mask</span><span class="p">[</span><span class="n">dau</span><span class="o">.</span><span class="n">mask_addition_if_totally_eliminated</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">False</span>
    
    
    
    <span class="c1"># new node ids to index into</span>
    <span class="n">previous_nodes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)</span>
    <span class="n">new_node_ids</span> <span class="o">=</span> <span class="n">previous_nodes</span> <span class="o">-</span> <span class="n">tenu</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">debug_time</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New nodes id time: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">st</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;new_node_ids = </span><span class="si">{</span><span class="n">new_node_ids</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
    <span class="c1"># find the edges to keep:</span>
    <span class="n">nodes_dropped</span> <span class="o">=</span> <span class="n">previous_nodes</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;nodes_dropped (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">nodes_dropped</span><span class="p">)</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">nodes_dropped</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
    <span class="k">if</span> <span class="n">debug_time</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node dropped time: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">st</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
    <span class="n">edge_idx_keep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">((</span><span class="n">tenu</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">nodes_dropped</span><span class="p">,</span><span class="n">return_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                     <span class="o">|</span> <span class="n">tenu</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">nodes_dropped</span><span class="p">,</span><span class="n">return_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
    
    <span class="k">if</span> <span class="n">debug_time</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Edge_idx_keep time: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">st</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">edges_dropped</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[:,</span><span class="o">~</span><span class="n">edge_idx_keep</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;edges dropped (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">edges_dropped</span><span class="p">)</span><span class="si">}</span><span class="s2">)= </span><span class="si">{</span><span class="n">edges_dropped</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
    <span class="n">edges</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[:,</span><span class="n">edge_idx_keep</span><span class="p">]</span>
    <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span> <span class="o">=</span> <span class="n">new_node_ids</span><span class="p">[</span><span class="n">edges</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="n">debug_batch</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Before x adjustment&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.x.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.batch.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.ptr = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ptr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
    <span class="c1">#--fixing all the node attributes</span>
    <span class="n">keep_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">data</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">,:]</span>
    <span class="c1">#data.y = data.y[keep_mask]</span>
    
    <span class="k">if</span> <span class="n">debug_time</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting x data: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">st</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
<span class="c1">#     if verbose:</span>
<span class="c1">#         print(f&quot;keep_mask = {keep_mask}&quot;)</span>
    <span class="k">if</span> <span class="n">debug_batch</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;After x adjustment&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.x.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.batch.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.ptr = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ptr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
    
    <span class="k">if</span> <span class="n">node_attributes_to_adjust</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">node_attributes_to_adjust</span><span class="p">:</span>
            <span class="n">curr_val</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">curr_val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">curr_val</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">])</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="s2">&quot;batch&quot;</span><span class="p">:</span>
                    <span class="k">pass</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                    
            <span class="k">if</span> <span class="n">debug_time</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting attribute </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">st</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            
    <span class="c1"># -- resolving the ptr</span>
    <span class="n">dau</span><span class="o">.</span><span class="n">set_ptr</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">debug_time</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting pointer: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">st</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">debug_batch</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AFter node attributes adjustment&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.x.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.batch.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.ptr = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ptr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        
    
     
    <span class="k">return</span> <span class="n">data</span></div>

<div class="viewcode-block" id="pool_idx_stacked"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.pool_idx_stacked">[docs]</a><span class="k">def</span> <span class="nf">pool_idx_stacked</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">pool_name</span> <span class="o">=</span> <span class="s2">&quot;pool1&quot;</span><span class="p">,</span>
    <span class="n">return_n_limbs_for_neuron</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_adjustment</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: To generate a vector that represents the </span>
<span class="sd">    mapping of nodes to unique limbs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pool1</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">pool_name</span><span class="p">)</span>
    <span class="n">n_limbs_for_neuron</span> <span class="o">=</span> <span class="n">pool1</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">ptr</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="n">return_n_limbs_for_neuron</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">n_limbs_for_neuron</span>
    <span class="n">adjust</span> <span class="o">=</span> <span class="p">(</span><span class="n">tenu</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">n_limbs_for_neuron</span><span class="p">)[</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">]</span> <span class="o">-</span> <span class="n">n_limbs_for_neuron</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">return_adjustment</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">adjust</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span>  <span class="n">adjust</span> <span class="o">+</span> <span class="n">pool1</span></div>

<div class="viewcode-block" id="drop_limbs"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.drop_limbs">[docs]</a><span class="k">def</span> <span class="nf">drop_limbs</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">p</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">clone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">limb_map_attribute</span> <span class="o">=</span> <span class="s2">&quot;pool1&quot;</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: To drop limbs randomly from a dataset</span>

<span class="sd">    Pseudocode: </span>
<span class="sd">    1) Get a mask for the limbs</span>
<span class="sd">    2) Turn the mask of the limbs into a mask for the nodes</span>
<span class="sd">    3) Use drop_nodes function</span>
<span class="sd">    </span>
<span class="sd">    Ex: </span>
<span class="sd">    new_d = dau.drop_limbs(</span>
<span class="sd">        data = dau.example_data_obj(),</span>
<span class="sd">        verbose = True,</span>
<span class="sd">        p = 0.3</span>
<span class="sd">    )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">debug_verbose</span> <span class="o">=</span> <span class="kc">False</span>
    
    <span class="k">if</span> <span class="n">debug_verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Beginning of drop limbs&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.x.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.batch.shape = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data.ptr = </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ptr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">pool1</span> <span class="o">=</span> <span class="n">dau</span><span class="o">.</span><span class="n">pool_idx_stacked</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">limb_map_attribute</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">debug_verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pool1.shape = </span><span class="si">{</span><span class="n">pool1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">n_limbs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pool1</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_limbs = </span><span class="si">{</span><span class="n">n_limbs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tenu</span><span class="o">.</span><span class="n">random_mask</span><span class="p">(</span><span class="n">n_limbs</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
        
    <span class="n">limb_idx_to_drop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_limbs</span><span class="p">)[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">node_mask</span> <span class="o">=</span> <span class="n">tenu</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">pool1</span><span class="p">,</span><span class="n">limb_idx_to_drop</span><span class="p">,</span><span class="n">return_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">debug_verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;limb_idx_to_drop (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">limb_idx_to_drop</span><span class="p">)</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">limb_idx_to_drop</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;node_mask = </span><span class="si">{</span><span class="n">node_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">dau</span><span class="o">.</span><span class="n">drop_nodes</span><span class="p">(</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">mask</span><span class="o">=</span><span class="n">node_mask</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">clone</span><span class="o">=</span><span class="n">clone</span><span class="p">,</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span><span class="p">,</span>
    <span class="p">)</span></div>




<span class="n">clone_default</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="Compose"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.Compose">[docs]</a><span class="k">class</span> <span class="nc">Compose</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="Compose.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.Compose.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span><span class="n">clone</span><span class="o">=</span><span class="n">clone_default</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clone</span> <span class="o">=</span> <span class="n">clone</span></div>

<div class="viewcode-block" id="Compose.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.Compose.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">aug</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span></div></div>
    
<div class="viewcode-block" id="NodeFeatureNoise"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeFeatureNoise">[docs]</a><span class="k">class</span> <span class="nc">NodeFeatureNoise</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="NodeFeatureNoise.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeFeatureNoise.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">amplitude</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span><span class="n">clone</span><span class="o">=</span><span class="n">clone_default</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">amplitude</span> <span class="o">=</span> <span class="n">amplitude</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clone</span> <span class="o">=</span> <span class="n">clone</span></div>
        
<div class="viewcode-block" id="NodeFeatureNoise.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeFeatureNoise.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">data</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">tenu</span><span class="o">.</span><span class="n">add_noise</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span>
                                <span class="n">amplitude</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">amplitude</span><span class="p">,</span>
                                <span class="n">seed</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span></div></div>
    
    
<div class="viewcode-block" id="NodeFeatureMask"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeFeatureMask">[docs]</a><span class="k">class</span> <span class="nc">NodeFeatureMask</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="NodeFeatureMask.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeFeatureMask.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span><span class="n">clone</span><span class="o">=</span><span class="n">clone_default</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clone</span> <span class="o">=</span> <span class="n">clone</span></div>
<div class="viewcode-block" id="NodeFeatureMask.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeFeatureMask.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">data</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">[:,</span><span class="n">tenu</span><span class="o">.</span><span class="n">random_mask</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">data</span></div></div>
    
<div class="viewcode-block" id="NodeDrop"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeDrop">[docs]</a><span class="k">class</span> <span class="nc">NodeDrop</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="NodeDrop.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeDrop.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span><span class="n">clone</span><span class="o">=</span><span class="n">clone_default</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clone</span> <span class="o">=</span> <span class="n">clone</span></div>
<div class="viewcode-block" id="NodeDrop.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.NodeDrop.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Ex: </span>
<span class="sd">        d = dau.example_data_obj()</span>
<span class="sd">        dau.NodeDrop(p = 0.5)(d,verbose =True)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">dau</span><span class="o">.</span><span class="n">drop_nodes</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span>
                    <span class="n">clone</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span><span class="p">,)</span></div></div>
    
<div class="viewcode-block" id="LimbDrop"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.LimbDrop">[docs]</a><span class="k">class</span> <span class="nc">LimbDrop</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<div class="viewcode-block" id="LimbDrop.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.LimbDrop.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span><span class="n">clone</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clone</span> <span class="o">=</span> <span class="n">clone</span></div>
<div class="viewcode-block" id="LimbDrop.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.LimbDrop.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Ex: </span>
<span class="sd">        d = dau.example_data_obj()</span>
<span class="sd">        dau.NodeDrop(p = 0.5)(d,verbose =True)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">dau</span><span class="o">.</span><span class="n">drop_limbs</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span>
                    <span class="n">clone</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span><span class="p">,)</span></div></div>
    
<div class="viewcode-block" id="compose_augmentation"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.data_augmentation_utils.compose_augmentation">[docs]</a><span class="k">def</span> <span class="nf">compose_augmentation</span><span class="p">(</span>
    <span class="n">augmentations</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">augmentations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">augmentations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">augmentations</span> <span class="o">=</span> <span class="n">nu</span><span class="o">.</span><span class="n">convert_to_array_like</span><span class="p">(</span><span class="n">augmentations</span><span class="p">)</span>
    <span class="n">aug_func</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">augmentations</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;str&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">k</span><span class="p">)):</span>
            <span class="n">aug_func</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dau</span><span class="p">,</span><span class="n">k</span><span class="p">)(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">aug_func</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">dau</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">aug_func</span><span class="p">)</span></div>
<span class="w">    </span>
<span class="w">    </span>
<span class="w">    </span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">class NodeDrop(nn.Module):</span>
<span class="sd">    def __init__(self, p=0.05):</span>
<span class="sd">        super().__init__()</span>
<span class="sd">        self.p = p</span>

<span class="sd">    def forward(self, data):</span>
<span class="sd">        x = data.x</span>
<span class="sd">        y = data.y</span>
<span class="sd">        train_mask = data.train_mask</span>
<span class="sd">        test_mask = data.test_mask</span>
<span class="sd">        edge_idx = data.edge_index</span>

<span class="sd">        idx = torch.empty(x.size(0)).uniform_(0, 1)</span>
<span class="sd">        train_mask[torch.where(idx &lt; self.p)] = 0</span>
<span class="sd">        test_mask[torch.where(idx &lt; self.p)] = 0</span>
<span class="sd">        new_data = tg.data.Data(x=x, edge_index=edge_idx, y=y, train_mask=train_mask, test_mask=test_mask)</span>

<span class="sd">        return new_data</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="c1">#--- from pytorch_tools ---</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">geometric_dataset_utils</span> <span class="k">as</span> <span class="n">gdu</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">tensor_utils</span> <span class="k">as</span> <span class="n">tenu</span>

<span class="c1">#--- from python_tools ---</span>
<span class="kn">from</span> <span class="nn">python_tools</span> <span class="kn">import</span> <span class="n">numpy_utils</span> <span class="k">as</span> <span class="n">nu</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">data_augmentation_utils</span> <span class="k">as</span> <span class="n">dau</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Brendan Celii.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>