<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pytorch_tools.hierarchical_utils &mdash; pytorch_tools  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            pytorch_tools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">pytorch_tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pytorch_tools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pytorch_tools.hierarchical_utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pytorch_tools.hierarchical_utils</h1><div class="highlight"><pre>
<span></span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span><span class="p">,</span><span class="n">global_add_pool</span><span class="p">,</span><span class="n">global_mean_pool</span><span class="p">,</span><span class="n">global_sort_pool</span><span class="p">,</span><span class="n">global_max_pool</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span><span class="c1">#torch modules</span>
<span class="c1">#from torch_geometric.nn import GCNConv</span>


<span class="c1">#custom modules</span>

<div class="viewcode-block" id="GCNHierarchicalClassifier"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.hierarchical_utils.GCNHierarchicalClassifier">[docs]</a><span class="k">class</span> <span class="nc">GCNHierarchicalClassifier</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: To run a GCN network that</span>
<span class="sd">    has a middle step that hierarchically pools</span>
<span class="sd">    nodes together and runs a classification on them</span>
<span class="sd">    and returns both the overall classification and the node classification</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
<div class="viewcode-block" id="GCNHierarchicalClassifier.__init__"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.hierarchical_utils.GCNHierarchicalClassifier.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_num_node_features</span><span class="p">,</span>
        <span class="n">dataset_num_classes</span><span class="p">,</span>
        
        <span class="c1"># parameters for model architecture</span>
        <span class="n">n_hidden_channels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_hidden_channels_pool0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_layers_pool0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_hidden_channels_pool1</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_layers_pool1</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        
        <span class="c1">#-- classier of the architecture --</span>
        
        
        <span class="c1">#-- number of features added on for the intermediate pooling step --</span>
        <span class="n">num_node_features_pool1</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        
        <span class="c1">#hyper-parameters for the training</span>
        <span class="n">activation_function</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_bn_pool0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_bn_pool1</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        
        <span class="c1">#pooling parameters</span>
        <span class="n">global_pool_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">global_pool_weight</span> <span class="o">=</span> <span class="s2">&quot;node_weight&quot;</span><span class="p">,</span>
        
        
        
        <span class="c1"># parameters to control the flow of data through architecture</span>
        <span class="n">aggregate_layer_outputs</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">aggregate_layer_outputs_func</span> <span class="o">=</span> <span class="s2">&quot;concatenate&quot;</span><span class="p">,</span>
        <span class="n">residual_connections</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        
        <span class="c1"># for applyin any edge weights</span>
        <span class="n">edge_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">edge_weight_name</span> <span class="o">=</span> <span class="s2">&quot;edge_weight&quot;</span><span class="p">,</span>
        <span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        
        <span class="c1"># linear layer training</span>
        <span class="n">dropout_p</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">dropout_p_pool0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dropout_p_pool1</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_lin_pool1</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>

        <span class="n">super_node_pool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        
        <span class="n">return_pool_after_pool1</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_pool_after_pool1_method</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        
        <span class="n">linear_clf_n_layers_pool0</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">linear_clf_n_layers_pool1</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        
        <span class="n">append_max_pool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        
        <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">super_node_pool</span> <span class="o">=</span> <span class="n">super_node_pool</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">return_pool_after_pool1</span> <span class="o">=</span> <span class="n">return_pool_after_pool1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_pool_after_pool1_method</span> <span class="o">=</span> <span class="n">return_pool_after_pool1_method</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bn</span> <span class="o">=</span> <span class="n">use_bn</span>
        
        <span class="k">if</span> <span class="n">use_bn_pool0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_bn_pool0</span> <span class="o">=</span> <span class="n">use_bn</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_bn_pool0</span> <span class="o">=</span> <span class="n">use_bn_pool0</span>
        
        <span class="k">if</span> <span class="n">use_bn_pool1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_bn_pool1</span> <span class="o">=</span> <span class="n">use_bn</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_bn_pool1</span> <span class="o">=</span> <span class="n">use_bn_pool1</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">activation_function</span><span class="p">)</span>
        
        <span class="c1"># -- for the pooling --</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_type</span> <span class="o">=</span> <span class="n">global_pool_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">gtu</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="n">global_pool_type</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span> <span class="o">=</span> <span class="n">global_pool_weight</span>
        
        <span class="c1"># --- control of flow parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residual_connections</span> <span class="o">=</span> <span class="n">residual_connections</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span> <span class="o">=</span> <span class="n">aggregate_layer_outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs_func</span> <span class="o">=</span> <span class="n">aggregate_layer_outputs_func</span>
        
        
        <span class="c1"># --- for the edge weights ---</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span> <span class="o">=</span> <span class="n">edge_weight</span>
        <span class="k">if</span> <span class="n">add_self_loops</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span> <span class="o">=</span> <span class="n">add_self_loops</span>
            
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;self.add_self_loops = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight_name</span> <span class="o">=</span> <span class="n">edge_weight_name</span>
        
        <span class="k">if</span> <span class="n">dropout_p_pool0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dropout_p_pool0</span> <span class="o">=</span> <span class="n">dropout_p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_p_pool0</span> <span class="o">=</span> <span class="n">dropout_p_pool0</span>
        
        <span class="k">if</span> <span class="n">dropout_p_pool1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dropout_p_pool1</span> <span class="o">=</span> <span class="n">dropout_p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_p_pool1</span> <span class="o">=</span> <span class="n">dropout_p_pool1</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">num_node_features_pool1</span> <span class="o">=</span> <span class="n">num_node_features_pool1</span>
        
        
        <span class="bp">self</span><span class="o">.</span><span class="n">use_lin_pool1</span> <span class="o">=</span> <span class="n">use_lin_pool1</span>
        <span class="c1"># --- architecture ----</span>
        <span class="n">n_input_layer</span> <span class="o">=</span> <span class="n">dataset_num_node_features</span>
        
        <span class="n">n_hidden_channels_for_aggregator</span> <span class="o">=</span> <span class="p">[]</span>
        
        
        <span class="c1"># for the pooling operations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">append_max_pool</span> <span class="o">=</span> <span class="n">append_max_pool</span>
        <span class="k">for</span> <span class="n">pool_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span><span class="p">):</span>
            
            <span class="n">suffix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span>
            
            <span class="n">normalize</span> <span class="o">=</span> <span class="ow">not</span> <span class="p">((</span><span class="n">pool_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">super_node_pool</span><span class="p">)</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">, normalize = </span><span class="si">{</span><span class="n">normalize</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="c1"># sets up the number of hidden channels</span>
            <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_hidden_channels</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">n_hidden_channels_pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="n">n_hidden_channels</span>
                
            <span class="c1">#sets up the number of pooling layers requested</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">nu</span><span class="o">.</span><span class="n">is_array_like</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">):</span>
                <span class="n">n_layers_pool</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_layers</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">n_layers_pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">n_layers_pool</span> <span class="o">=</span> <span class="n">n_layers</span>
                <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_hidden_channels_pool</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">n_layers_pool</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_layers_pool</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">)</span>
                
            
            <span class="n">n_hidden_channels_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">n_input_layer</span><span class="p">,</span><span class="n">n_hidden_channels_pool</span><span class="p">])</span>
            
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pool </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> n_hidden_channels_pool = </span><span class="si">{</span><span class="n">n_hidden_channels_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
            <span class="c1"># Creating the convolutional and batch layers</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                
                <span class="n">n_hidden_channels_for_aggregator</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
                
                <span class="n">n_input</span> <span class="o">=</span> <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">n_output</span> <span class="o">=</span> <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">GCNConv</span><span class="p">(</span>
                    <span class="n">n_input</span><span class="p">,</span> 
                    <span class="n">n_output</span><span class="p">,</span>
                    <span class="n">add_self_loops</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">add_self_loops</span><span class="p">,</span>
                    <span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">,</span>
                <span class="p">))</span>
                       
                <span class="n">curr_bn</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;self.use_bn</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">curr_bn</span><span class="p">:</span> 
                    <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span>
                                <span class="n">n_output</span><span class="p">,</span>
                                <span class="n">track_running_stats</span><span class="o">=</span><span class="n">track_running_stats</span>
                    <span class="p">))</span>
                    
            <span class="c1"># Register the number of layers for this pooling stage</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;n_conv</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">n_layers_pool</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">pool_idx</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">n_extra_features</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num_node_features_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_extra_features</span><span class="o">=</span> <span class="mi">0</span>
                
                
            <span class="c1"># ---- ********** this is changed where now feed in the number of classes instead of previous layer size ---</span>
            
            
            <span class="c1"># now have to do the linear layers</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span><span class="p">:</span>
                <span class="n">lin_n_layers</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">n_hidden_channels_for_aggregator</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lin_n_layers</span> <span class="o">=</span> <span class="n">n_hidden_channels_pool</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                
            <span class="k">if</span> <span class="n">append_max_pool</span><span class="p">:</span>
                <span class="n">lin_n_layers</span> <span class="o">=</span> <span class="n">lin_n_layers</span><span class="o">*</span><span class="mi">2</span>
            
            <span class="c1"># Creating the linear classification layers</span>
            <span class="k">if</span> <span class="n">pool_idx</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lin_pool1</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;lin</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">ClassifierBase</span><span class="p">(</span>
                        <span class="n">n_classes</span> <span class="o">=</span> <span class="n">dataset_num_classes</span><span class="p">,</span>
                        <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">lin_n_layers</span><span class="p">,</span> 
                        <span class="n">n_hidden_layers</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;linear_clf_n_layers</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">),</span>
                        <span class="n">use_bn</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                        <span class="n">softmax</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                        <span class="n">dropout</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;dropout_p</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="p">)</span>
            
            <span class="n">n_input_layer</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">dataset_num_classes</span> <span class="o">+</span> <span class="n">n_extra_features</span>
                <span class="p">)</span></div>
            
            
    
<div class="viewcode-block" id="GCNHierarchicalClassifier.encode"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.hierarchical_utils.GCNHierarchicalClassifier.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">debug_encode</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">debug_nan</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">debug_conv</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">):</span>
<span class="w">        </span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Purpose: To pass dta through all of the gcn layers</span>
<span class="sd">        and classifier layers and return the following:</span>
<span class="sd">        </span>
<span class="sd">        Pseudocode:</span>
<span class="sd">        1) pool0 GCN layer</span>
<span class="sd">        2) Pool the nodes together into limbs</span>
<span class="sd">        2) Feed into classifier (save the outputs and y)</span>
<span class="sd">        3) concatenate x_pool1 to features</span>
<span class="sd">        4) pool1 GCN layer</span>
<span class="sd">        5) Pool the nodes together</span>
<span class="sd">        6) Pass through classifier</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">#print(f&quot;debug_nan = {debug_nan}&quot;)</span>
        
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;ptr&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        
        
        
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">ptr</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ptr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)],</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        
        <span class="n">all_layer_x</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pool_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span><span class="p">):</span>
            
            <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Working on Pool </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
            <span class="n">suffix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">n_conv</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;n_conv</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="c1">#1) GCN layers</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conv</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Working on Layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weight</span><span class="p">:</span>
                    <span class="n">edge_weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_weight_name</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">edge_weight</span> <span class="o">=</span> <span class="kc">None</span>
                    
                <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;edge_weight iter </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">edge_weight</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
                    <span class="n">x_old</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                
                <span class="k">if</span> <span class="n">debug_conv</span><span class="p">:</span>
                    <span class="n">conv_layer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">bias</span><span class="p">,</span><span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">conv_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bias = </span><span class="si">{</span><span class="n">bias</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;params = </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;edge_index = </span><span class="si">{</span><span class="n">edge_index</span><span class="o">.</span><span class="n">T</span><span class="p">[:</span><span class="mi">12</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> BEFORE conv (</span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">x</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;conv</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span>
                                                     <span class="n">edge_weight</span><span class="o">=</span><span class="n">edge_weight</span><span class="p">)</span>
                    
                <span class="k">if</span> <span class="n">debug_conv</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> after conv (</span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">x</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output gcn, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
                <span class="n">curr_bn</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;self.use_bn</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">curr_bn</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using bn iter </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;bn</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
                    
                    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output batch norm, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                            
                <span class="c1">#print(f&quot;inside x pool_idx {pool_idx} after BN: {x}&quot;)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_conv</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span> <span class="c1"># and (pool_idx == self.n_pool - 1):</span>
                    <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using act_fun </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    
                    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output acti norm, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="c1">#print(f&quot;inside x pool_idx {pool_idx} after act: {x}&quot;)</span>
                
                <span class="c1">#print(f&quot;End of convolution loop x pool_idx {pool_idx}: {x}&quot;)</span>
                    
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span><span class="p">:</span>
                    <span class="n">all_layer_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                    
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_connections</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">x_old</span><span class="p">])</span>
            
                
            
            <span class="c1"># pooling the nodes together</span>
            <span class="n">weight_values</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span><span class="si">}</span><span class="s2">_pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">weight_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">weight_values</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_weight</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
                
                
            <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Right before pooling weight_values = </span><span class="si">{</span><span class="n">weight_values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weight_values = </span><span class="si">{</span><span class="n">weight_values</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                
            
            <span class="c1">#doing the aggregation of x&#39;s if aggregating all outputs</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">==</span> <span class="n">pool_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;About to aggregate layers if requested&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs_func</span> <span class="o">==</span> <span class="s2">&quot;concatenate&quot;</span><span class="p">:</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">all_layer_x</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_layer_outputs_func</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">all_layer_x</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">all_layer_x</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                           
            <span class="c1"># Pooling the nodes together</span>
            <span class="n">next_pool</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;pool</span><span class="si">{</span><span class="n">pool_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">pool_vec</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">next_pool</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">pool_vec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">pool_vec</span> <span class="o">=</span> <span class="n">batch</span>
                <span class="n">need_batch</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">need_batch</span> <span class="o">=</span> <span class="kc">True</span>
                
            <span class="k">if</span> <span class="n">debug_encode</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Right before pool func: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
            <span class="c1">#print(f&quot;x outside loop pool_idx = {pool_idx}: {x}&quot;)</span>
<span class="c1">#             print(f&quot;x.shape = {x.shape}&quot;)</span>
<span class="c1">#             print(f&quot;pool_vec.shape = {pool_vec.shape}&quot;)</span>
<span class="c1">#             print(f&quot;weight_values = {weight_values.shape}&quot;)</span>
            
            <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output x, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">weight_values</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output weight_values, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">pool_vec</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output pool_vec, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                
                    
            
            <span class="k">if</span> <span class="n">pool_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">super_node_pool</span><span class="p">:</span>
                <span class="c1">#print(f&quot;Using the super node pooling&quot;)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ptr</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_max_pool</span><span class="p">:</span>
                    <span class="n">x_max</span> <span class="o">=</span> <span class="n">global_max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">pool_vec</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_pool_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_vec</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">weight_values</span><span class="p">,</span><span class="n">debug_nan</span><span class="o">=</span><span class="n">debug_nan</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_max_pool</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">x_max</span><span class="p">])</span>
                    
                
            
            <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output weighted pool, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">pool_idx</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lin_pool1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;lin</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output linear layer, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nan output softmax, pool_idx </span><span class="si">{</span><span class="n">pool_idx</span><span class="si">}</span><span class="s2"> gnc layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">pool_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pool</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1">#raise Exception(&quot;&quot;)</span>
                <span class="k">return</span> <span class="n">x_0</span><span class="p">,</span><span class="n">x</span>
            
            <span class="n">x_0</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            
            <span class="n">x_pool</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;x_</span><span class="si">{</span><span class="n">next_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([]))</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">global_mean_pool</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">pool_vec</span><span class="p">)</span>
            <span class="n">ptr</span> <span class="o">=</span> <span class="n">gtu</span><span class="o">.</span><span class="n">ptr_from_pool_tensor</span><span class="p">(</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="p">)</span>
            <span class="c1"># need to fix the pointer</span>
            
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_pool_after_pool1</span><span class="p">:</span>
                <span class="c1">#print(f&quot;Returning ealry&quot;)</span>
                <span class="c1">#print(f&quot;x_0.shape = {x_0.shape}&quot;)</span>
                <span class="n">x_1</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">gtu</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;global_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">return_pool_after_pool1_method</span><span class="si">}</span><span class="s2">_pool&quot;</span><span class="p">)(</span><span class="n">x_0</span><span class="p">,</span><span class="n">batch</span><span class="p">)</span>
                <span class="c1">#print(f&quot;x_1.shape = {x_1.shape}&quot;)</span>
                <span class="k">return</span> <span class="n">x_0</span><span class="p">,</span><span class="n">x_1</span>
            
            <span class="c1">#print(f&quot;x_pool = {x_pool}&quot;)</span>
            <span class="k">if</span> <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;self.num_node_features_</span><span class="si">{</span><span class="n">next_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> 
                <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">x_pool</span><span class="p">])</span>
                
            
            
            <span class="c1">#getting new edge index</span>
            <span class="n">edge_index</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;edge_index_</span><span class="si">{</span><span class="n">next_pool</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span></div>
            
            
            
            
            
<div class="viewcode-block" id="GCNHierarchicalClassifier.forward"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.hierarchical_utils.GCNHierarchicalClassifier.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>
    
    
<span class="c1"># ----------- For doing the forward pass ----</span>


<span class="n">eps</span><span class="o">=</span><span class="mf">1e-13</span>


<span class="c1"># -- for helping compute the weighted loss --</span>

<div class="viewcode-block" id="hierarchical_loss"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.hierarchical_utils.hierarchical_loss">[docs]</a><span class="k">def</span> <span class="nf">hierarchical_loss</span><span class="p">(</span>
    <span class="n">loss_function</span><span class="p">,</span>
    <span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span>
    <span class="n">y1</span><span class="p">,</span><span class="n">y2</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">class_weights</span><span class="p">,</span>
    <span class="n">loss_pool1_weight_by_pool2_group</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">loss_pool1_weight</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">loss_pool2_weight</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">return_separate_loss</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">debug</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">debug_nan</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
    
    <span class="c1">#print(f&quot;loss_pool1_weight = {loss_pool1_weight}&quot;)</span>
    
    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output x1&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">y1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output y1&quot;</span><span class="p">)</span>
    <span class="n">loss_pool1</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x1</span> <span class="o">+</span> <span class="n">eps</span><span class="p">),</span> 
        <span class="n">y1</span><span class="p">,</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">class_weights</span><span class="p">,</span>
        <span class="n">reduction</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span>
        <span class="p">)</span>
    
    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">loss_pool1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output loss_pool1&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">debug</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x1= </span><span class="si">{</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;y1= </span><span class="si">{</span><span class="n">y1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">y1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output y1&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">loss_pool1_weight_by_pool2_group</span><span class="p">:</span>
        <span class="n">loss_pool1</span> <span class="o">=</span> <span class="n">loss_pool1</span> <span class="o">*</span> <span class="n">gtu</span><span class="o">.</span><span class="n">normalize_in_pool_from_pool_tensor</span><span class="p">(</span>
            <span class="n">global_mean_pool</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">pool1</span><span class="p">)</span>
        <span class="p">)</span>
        
        
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss_pool1</span> <span class="o">=</span> <span class="n">loss_pool1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span>
        
    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">loss_pool1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output loss_pool1&quot;</span><span class="p">)</span>
        
<span class="c1">#     if debug:</span>
<span class="c1">#         print(f&quot;data.x_pool1 = {data.x_pool1}&quot;)</span>

    <span class="n">loss_pool1</span> <span class="o">=</span> <span class="n">loss_pool1</span> <span class="o">*</span> <span class="n">loss_pool1_weight</span>

    <span class="c1"># need to adjust the  loss_pool1</span>
    
    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x2</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output x2&quot;</span><span class="p">)</span>
            
    <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">y2</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output y2&quot;</span><span class="p">)</span>

    <span class="n">loss_pool2</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x2</span> <span class="o">+</span> <span class="n">eps</span><span class="p">),</span> 
        <span class="n">y2</span><span class="p">,</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">class_weights</span><span class="p">,</span>
        <span class="n">reduction</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">*</span> <span class="n">loss_pool2_weight</span>
    
    <span class="n">loss_pool2</span> <span class="o">=</span> <span class="n">loss_pool2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">loss_pool1</span> <span class="o">=</span> <span class="n">loss_pool1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">return_separate_loss</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loss_pool1</span><span class="p">,</span> <span class="n">loss_pool2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loss_pool1</span> <span class="o">+</span> <span class="n">loss_pool2</span></div>


<div class="viewcode-block" id="forward_pass"><a class="viewcode-back" href="../../pytorch_tools.html#pytorch_tools.hierarchical_utils.forward_pass">[docs]</a><span class="k">def</span> <span class="nf">forward_pass</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">data_loader</span><span class="p">,</span>
    <span class="n">loss_pool1_weight_by_pool2_group</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">loss_pool1_weight</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">loss_pool2_weight</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">n_batches_per_update</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
    <span class="n">loss_function</span> <span class="o">=</span> <span class="s2">&quot;nll_loss&quot;</span><span class="p">,</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
    <span class="n">tensor_map</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weights</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">augmentations</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_predicted_labels</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_data_names</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_data_sources</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">features_to_return_1</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">features_to_return_2</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict_for_embed</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_df</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">debug_nan</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">debug</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Purpose: Want to generate y_pred/y_true or dataframes for </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># -- gets the actual loss function from str name---</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">loss_function</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">loss_function</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span><span class="n">loss_function</span><span class="p">)</span>
        
    <span class="c1"># -- creates composition of augemntations</span>
    <span class="k">if</span> <span class="n">augmentations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">aug_compose</span> <span class="o">=</span> <span class="n">dau</span><span class="o">.</span><span class="n">compose_augmentation</span><span class="p">(</span><span class="n">augmentations</span><span class="p">)</span>
        
    <span class="c1"># Puts model into modes to compute gradients or not</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
    <span class="n">y_pred_list_1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_true_list_1</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">embeddings_1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels_1</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">y_pred_list_2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_true_list_2</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">embeddings_2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels_2</span> <span class="o">=</span> <span class="p">[]</span>
    
    
    <span class="c1"># for storing all of the attributes requested to be returned</span>
    <span class="k">if</span> <span class="n">features_to_return_1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;str&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">features_to_return_1</span><span class="p">)):</span>
            <span class="n">features_to_return_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">features_to_return_1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">features_to_return_1</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">if</span> <span class="n">features_to_return_2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;str&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">features_to_return_2</span><span class="p">)):</span>
            <span class="n">features_to_return_2</span> <span class="o">=</span> <span class="p">[</span><span class="n">features_to_return_2</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">features_to_return_2</span> <span class="o">=</span> <span class="p">[]</span>
        
    
    <span class="k">if</span> <span class="n">return_data_names</span><span class="p">:</span>
        <span class="n">features_to_return_1</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span>
        <span class="n">features_to_return_2</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span>
        
    <span class="k">if</span> <span class="n">return_data_sources</span><span class="p">:</span>
        <span class="n">features_to_return_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;data_source&quot;</span><span class="p">)</span>
        <span class="n">features_to_return_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;data_source&quot;</span><span class="p">)</span>
        
        
    <span class="n">features_dict_1</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:[]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">features_to_return_1</span><span class="p">}</span>
    <span class="n">features_dict_2</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:[]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">features_to_return_2</span><span class="p">}</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss_1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss_2</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss_for_update</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">jj</span><span class="p">,</span><span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
        
        
        <span class="k">if</span> <span class="n">debug_nan</span> <span class="ow">or</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">------ iteration </span><span class="si">{</span><span class="n">jj</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># -- Running the augmentations on the model ---</span>
        <span class="k">if</span> <span class="n">augmentations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1">#print(f&quot;Data before augmentation = \n\t{data.x}&quot;)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">aug_compose</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="c1">#print(f&quot;Data after augmentation = \n\t{data.x}\n\n\n&quot;)</span>
            
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output&quot;</span><span class="p">)</span>
            
        <span class="c1"># -- get the output of the model</span>
        <span class="n">x1</span><span class="p">,</span><span class="n">x2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">debug_nan</span><span class="o">=</span><span class="n">debug_nan</span><span class="p">)</span>
        
        <span class="c1"># --- getting what the y values should have been</span>
        <span class="n">y2</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">squeeze_</span><span class="p">()</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="n">y2</span><span class="p">[</span><span class="n">global_mean_pool</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">pool1</span><span class="p">)]</span>
        
<span class="c1">#         if debug:</span>
<span class="c1">#             print(f&quot;y2 = {y2}&quot;)</span>
<span class="c1">#             print(f&quot;y1 = {y1}&quot;)</span>
        
        <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x1= </span><span class="si">{</span><span class="n">x1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x1</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x2= </span><span class="si">{</span><span class="n">x2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tenu</span><span class="o">.</span><span class="n">isnan_any</span><span class="p">(</span><span class="n">x2</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan output&quot;</span><span class="p">)</span>
                
        <span class="c1"># --- computing hte loss if in training mode --</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            
            <span class="c1"># --- determining the 2 loss functions ----</span>
            <span class="n">curr_loss_1</span><span class="p">,</span><span class="n">curr_loss_2</span> <span class="o">=</span> <span class="n">hru</span><span class="o">.</span><span class="n">hierarchical_loss</span><span class="p">(</span>
                <span class="n">loss_function</span><span class="p">,</span>
                <span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span>
                <span class="n">y1</span><span class="p">,</span><span class="n">y2</span><span class="p">,</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span>
                <span class="n">loss_pool1_weight_by_pool2_group</span> <span class="o">=</span> <span class="n">loss_pool1_weight_by_pool2_group</span><span class="p">,</span>
                <span class="n">loss_pool1_weight</span> <span class="o">=</span> <span class="n">loss_pool1_weight</span><span class="p">,</span>
                <span class="n">loss_pool2_weight</span> <span class="o">=</span> <span class="n">loss_pool2_weight</span><span class="p">,</span>
                <span class="n">return_separate_loss</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                <span class="n">debug</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">debug_nan</span> <span class="o">=</span> <span class="n">debug_nan</span><span class="p">,</span>
                <span class="p">)</span>
            
            <span class="n">curr_loss</span> <span class="o">=</span> <span class="n">curr_loss_1</span> <span class="o">+</span> <span class="n">curr_loss_2</span>
            
            <span class="n">loss_for_update</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_loss</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">curr_loss</span>
            
            <span class="n">loss_1</span><span class="o">+=</span> <span class="n">curr_loss_1</span>
            <span class="n">loss_2</span><span class="o">+=</span> <span class="n">curr_loss_2</span>
            
            <span class="c1"># -- only performing a backpropogation step ever [n_batches_per_update] batches</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">jj</span> <span class="o">%</span> <span class="n">n_batches_per_update</span> <span class="o">==</span> <span class="n">n_batches_per_update</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">debug</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;updating&quot;</span><span class="p">)</span>
                <span class="n">t_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">loss_for_update</span><span class="p">)</span>
                <span class="n">t_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Derive gradients.</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># Update parameters based on gradients.</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Clear gradients.</span>
                <span class="n">loss_for_update</span><span class="o">=</span><span class="p">[]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">debug</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not updating&quot;</span><span class="p">)</span>
                    
            <span class="k">if</span> <span class="n">debug_nan</span><span class="p">:</span>
                <span class="n">paru</span><span class="o">.</span><span class="n">print_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss = </span><span class="si">{</span><span class="n">loss</span><span class="o">/</span><span class="p">(</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">paru</span><span class="o">.</span><span class="n">isnan_in_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Nan parameters&quot;</span><span class="p">)</span>
                    
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">curr_loss_1</span><span class="p">,</span><span class="n">curr_loss_2</span> <span class="o">=</span> <span class="n">hru</span><span class="o">.</span><span class="n">hierarchical_loss</span><span class="p">(</span>
                    <span class="n">loss_function</span><span class="p">,</span>
                    <span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span>
                    <span class="n">y1</span><span class="p">,</span><span class="n">y2</span><span class="p">,</span>
                    <span class="n">data</span><span class="p">,</span>
                    <span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span>
                    <span class="n">loss_pool1_weight_by_pool2_group</span> <span class="o">=</span> <span class="n">loss_pool1_weight_by_pool2_group</span><span class="p">,</span>
                    <span class="n">loss_pool1_weight</span> <span class="o">=</span> <span class="n">loss_pool1_weight</span><span class="p">,</span>
                    <span class="n">loss_pool2_weight</span> <span class="o">=</span> <span class="n">loss_pool2_weight</span><span class="p">,</span>
                    <span class="n">return_separate_loss</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                    <span class="n">debug_nan</span> <span class="o">=</span> <span class="n">debug_nan</span><span class="p">,</span>
                    <span class="p">)</span>
                
                <span class="n">curr_loss</span> <span class="o">=</span> <span class="n">curr_loss_1</span> <span class="o">+</span> <span class="n">curr_loss_2</span>
            
                <span class="n">loss</span> <span class="o">+=</span> <span class="n">curr_loss</span>

                <span class="n">loss_1</span><span class="o">+=</span> <span class="n">curr_loss_1</span>
                <span class="n">loss_2</span><span class="o">+=</span> <span class="n">curr_loss_2</span>
                
                
            <span class="c1"># computing the </span>
            <span class="n">y_pred_1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">y_pred_list_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred_1</span><span class="p">)</span>
            <span class="n">y_true_list_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>

            <span class="n">y_pred_2</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">y_pred_list_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred_2</span><span class="p">)</span>
            <span class="n">y_true_list_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span>
            
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;embed&quot;</span><span class="p">:</span>

            <span class="n">curr_embed_1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">embeddings_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_embed_1</span><span class="p">)</span>
            <span class="n">labels_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y1</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            
            
            <span class="c1">#print(f&quot;curr_embed_1.shape = {curr_embed_1.shape}&quot;)</span>
            
            <span class="n">curr_embed_2</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">embeddings_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_embed_2</span><span class="p">)</span>
            <span class="n">labels_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y2</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            
            <span class="c1">#print(f&quot;curr_embed_2.shape = {curr_embed_2.shape}&quot;)</span>
            
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features_dict_1</span><span class="p">:</span>
                <span class="n">curr_data</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
                <span class="k">if</span> <span class="s2">&quot;pool&quot;</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">curr_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">curr_data</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">index_vec</span> <span class="o">=</span> <span class="n">gtu</span><span class="o">.</span><span class="n">global_mean_pool</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">pool1</span><span class="p">)</span>
                    <span class="n">curr_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">curr_data</span><span class="p">)[</span><span class="n">index_vec</span><span class="p">]</span>

                <span class="n">features_dict_1</span><span class="p">[</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_data</span><span class="p">)</span>
                <span class="c1">#print(f&quot;{f}: {curr_data.shape}&quot;)</span>
            
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features_dict_2</span><span class="p">:</span>
                <span class="n">features_dict_2</span><span class="p">[</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">f</span><span class="p">))</span>
                
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Unknown mode&quot;</span><span class="p">)</span>
            
            
    <span class="c1"># -------- Preparing the Return Value ------ </span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loss_1</span><span class="o">/</span><span class="p">(</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">loss_2</span><span class="o">/</span><span class="p">(</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
        <span class="n">y_pred_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_pred_list_1</span><span class="p">)</span>
        <span class="n">y_true_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_true_list_1</span><span class="p">)</span>
        
        <span class="n">y_pred_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_pred_list_2</span><span class="p">)</span>
        <span class="n">y_true_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_true_list_2</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;----Pool 1 metric Dict ---&quot;</span><span class="p">)</span>
        <span class="n">met_dict_1</span> <span class="o">=</span> <span class="n">evu</span><span class="o">.</span><span class="n">metric_dict</span><span class="p">(</span>
                    <span class="n">y_true_1</span><span class="p">,</span>
                    <span class="n">y_pred_1</span><span class="p">,</span>
                    <span class="n">tensor_map</span><span class="o">=</span><span class="n">tensor_map</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                    <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;----Pool 2 metric Dict ---&quot;</span><span class="p">)</span>
        <span class="n">met_dict_2</span> <span class="o">=</span> <span class="n">evu</span><span class="o">.</span><span class="n">metric_dict</span><span class="p">(</span>
                    <span class="n">y_true_2</span><span class="p">,</span>
                    <span class="n">y_pred_2</span><span class="p">,</span>
                    <span class="n">tensor_map</span><span class="o">=</span><span class="n">tensor_map</span><span class="p">,</span>
                    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">met_dict_1</span><span class="p">,</span>
                <span class="n">met_dict_2</span><span class="p">,</span>
                <span class="n">loss_1</span><span class="o">/</span><span class="p">(</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">loss_2</span><span class="o">/</span><span class="p">(</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span>
               <span class="p">)</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;embed&quot;</span><span class="p">:</span>
        <span class="n">embeddings_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">embeddings_1</span><span class="p">)</span>
        <span class="n">labels_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">labels_1</span><span class="p">)</span>
        
        <span class="n">embeddings_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">embeddings_2</span><span class="p">)</span>
        <span class="n">labels_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">labels_2</span><span class="p">)</span>
        
        <span class="n">return_value_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">embeddings_1</span><span class="p">),</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">labels_1</span><span class="p">),]</span>
        <span class="n">return_value_2</span> <span class="o">=</span> <span class="p">[</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">embeddings_2</span><span class="p">),</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">labels_2</span><span class="p">)]</span>
        
        <span class="n">return_value_names_1</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;embeddings&quot;</span><span class="p">,</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">,]</span>
        
        <span class="n">return_value_names_2</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;embeddings&quot;</span><span class="p">,</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">,]</span>
        
        <span class="k">if</span> <span class="n">return_predicted_labels</span><span class="p">:</span>
            <span class="n">return_value_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">embeddings_1</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">return_value_names_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;predicted_labels&quot;</span><span class="p">)</span>
            
            <span class="n">return_value_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">embeddings_2</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">return_value_names_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;predicted_labels&quot;</span><span class="p">)</span>
        
        
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features_dict_1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_dict_1</span><span class="p">[</span><span class="n">f</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">return_value_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">features_dict_1</span><span class="p">[</span><span class="n">f</span><span class="p">]))</span>
            <span class="n">return_value_names_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features_dict_2</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_dict_2</span><span class="p">[</span><span class="n">f</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">return_value_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">features_dict_2</span><span class="p">[</span><span class="n">f</span><span class="p">]))</span>
            <span class="n">return_value_names_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                
        <span class="n">return_dict_1</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">return_value_names_1</span><span class="p">,</span><span class="n">return_value_1</span><span class="p">)}</span>
        <span class="n">return_dict_2</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">return_value_names_2</span><span class="p">,</span><span class="n">return_value_2</span><span class="p">)}</span>
        
        <span class="k">if</span> <span class="n">return_df</span><span class="p">:</span>
            <span class="n">df_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embeddings_1</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">return_dict_1</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">df_1</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                
            <span class="n">df_2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embeddings_2</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">return_dict_2</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">df_2</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="k">return</span> <span class="n">df_1</span><span class="p">,</span><span class="n">df_2</span>
        <span class="k">if</span> <span class="n">return_dict_for_embed</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">return_dict_1</span><span class="p">,</span><span class="n">return_dict_2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">return_value_1</span><span class="p">,</span><span class="n">return_value_2</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span></div>
        
            
            
                
        
        
            
        
            
            
        
                
                
        
        
        
        
        
    
    
    
<span class="c1">#--- from pytorch_tools ---</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">data_augmentation_utils</span> <span class="k">as</span> <span class="n">dau</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">evaluation_utils</span> <span class="k">as</span> <span class="n">evu</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">geometric_tensor_utils</span> <span class="k">as</span> <span class="n">gtu</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">parameters_utils</span> <span class="k">as</span> <span class="n">paru</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">tensor_utils</span> <span class="k">as</span> <span class="n">tenu</span>
<span class="kn">from</span> <span class="nn">.geometric_models</span> <span class="kn">import</span> <span class="n">ClassifierBase</span>
<span class="kn">from</span> <span class="nn">.geometric_models_overload</span> <span class="kn">import</span> <span class="n">GCNConv</span>

<span class="c1">#--- from python_tools ---</span>
<span class="kn">from</span> <span class="nn">python_tools</span> <span class="kn">import</span> <span class="n">numpy_utils</span> <span class="k">as</span> <span class="n">nu</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">hierarchical_utils</span> <span class="k">as</span> <span class="n">hru</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Brendan Celii.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>